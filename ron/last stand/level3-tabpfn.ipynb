{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c28aef1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "🚀 Starting Level 1 training...\n",
      "🎯 Training for target BlendProperty1...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "🎯 Training for target BlendProperty2...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "🎯 Training for target BlendProperty3...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "🎯 Training for target BlendProperty4...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "🎯 Training for target BlendProperty5...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "🎯 Training for target BlendProperty6...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "🎯 Training for target BlendProperty7...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "🎯 Training for target BlendProperty8...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "🎯 Training for target BlendProperty9...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "🎯 Training for target BlendProperty10...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "\n",
      "📊 Level 1 MAPE Scores:\n",
      "  Ridge: 2.310334\n",
      "  Lasso: 2.149103\n",
      "  ElasticNet: 2.366510\n",
      "  BayesianRidge: 2.322658\n",
      "  Huber: 1.924173\n",
      "  RandomForest: 1.884861\n",
      "  ExtraTrees: 2.338880\n",
      "  AdaBoost: 2.707657\n",
      "  GradientBoost: 1.249835\n",
      "  Bagging: 2.506021\n",
      "  KNN: 4.413873\n",
      "  SVR: 3.336651\n",
      "  XGB: 1.870102\n",
      "  LGBM: 1.054876\n",
      "\n",
      "🔄 Stacking Level 1 outputs...\n",
      "\n",
      "🚀 Starting Level 2 stacking (MLP + TabPFN)...\n",
      "🧠 MLP stacking for BlendProperty1...\n",
      "    Fold 1/5\n",
      "    Fold 2/5\n",
      "    Fold 3/5\n",
      "    Fold 4/5\n",
      "    Fold 5/5\n",
      "🧠 MLP stacking for BlendProperty2...\n",
      "    Fold 1/5\n",
      "    Fold 2/5\n",
      "    Fold 3/5\n",
      "    Fold 4/5\n",
      "    Fold 5/5\n",
      "🧠 MLP stacking for BlendProperty3...\n",
      "    Fold 1/5\n",
      "    Fold 2/5\n",
      "    Fold 3/5\n",
      "    Fold 4/5\n",
      "    Fold 5/5\n",
      "🧠 MLP stacking for BlendProperty4...\n",
      "    Fold 1/5\n",
      "    Fold 2/5\n",
      "    Fold 3/5\n",
      "    Fold 4/5\n",
      "    Fold 5/5\n",
      "🧠 MLP stacking for BlendProperty5...\n",
      "    Fold 1/5\n",
      "    Fold 2/5\n",
      "    Fold 3/5\n",
      "    Fold 4/5\n",
      "    Fold 5/5\n",
      "🧠 MLP stacking for BlendProperty6...\n",
      "    Fold 1/5\n",
      "    Fold 2/5\n",
      "    Fold 3/5\n",
      "    Fold 4/5\n",
      "    Fold 5/5\n",
      "🧠 MLP stacking for BlendProperty7...\n",
      "    Fold 1/5\n",
      "    Fold 2/5\n",
      "    Fold 3/5\n",
      "    Fold 4/5\n",
      "    Fold 5/5\n",
      "🧠 MLP stacking for BlendProperty8...\n",
      "    Fold 1/5\n",
      "    Fold 2/5\n",
      "    Fold 3/5\n",
      "    Fold 4/5\n",
      "    Fold 5/5\n",
      "🧠 MLP stacking for BlendProperty9...\n",
      "    Fold 1/5\n",
      "    Fold 2/5\n",
      "    Fold 3/5\n",
      "    Fold 4/5\n",
      "    Fold 5/5\n",
      "🧠 MLP stacking for BlendProperty10...\n",
      "    Fold 1/5\n",
      "    Fold 2/5\n",
      "    Fold 3/5\n",
      "    Fold 4/5\n",
      "    Fold 5/5\n",
      "\n",
      "🔥 TabPFN stacking...\n",
      "🎯 TabPFN stacking for BlendProperty1...\n",
      "    Fold 1/5\n",
      "    Fold 2/5\n",
      "    Fold 3/5\n",
      "    Fold 4/5\n",
      "    Fold 5/5\n",
      "🎯 TabPFN stacking for BlendProperty2...\n",
      "    Fold 1/5\n",
      "    Fold 2/5\n",
      "    Fold 3/5\n",
      "    Fold 4/5\n",
      "    Fold 5/5\n",
      "🎯 TabPFN stacking for BlendProperty3...\n",
      "    Fold 1/5\n",
      "    Fold 2/5\n",
      "    Fold 3/5\n",
      "    Fold 4/5\n",
      "    Fold 5/5\n",
      "🎯 TabPFN stacking for BlendProperty4...\n",
      "    Fold 1/5\n",
      "    Fold 2/5\n",
      "    Fold 3/5\n",
      "    Fold 4/5\n",
      "    Fold 5/5\n",
      "🎯 TabPFN stacking for BlendProperty5...\n",
      "    Fold 1/5\n",
      "    Fold 2/5\n",
      "    Fold 3/5\n",
      "    Fold 4/5\n",
      "    Fold 5/5\n",
      "🎯 TabPFN stacking for BlendProperty6...\n",
      "    Fold 1/5\n",
      "    Fold 2/5\n",
      "    Fold 3/5\n",
      "    Fold 4/5\n",
      "    Fold 5/5\n",
      "🎯 TabPFN stacking for BlendProperty7...\n",
      "    Fold 1/5\n",
      "    Fold 2/5\n",
      "    Fold 3/5\n",
      "    Fold 4/5\n",
      "    Fold 5/5\n",
      "🎯 TabPFN stacking for BlendProperty8...\n",
      "    Fold 1/5\n",
      "    Fold 2/5\n",
      "    Fold 3/5\n",
      "    Fold 4/5\n",
      "    Fold 5/5\n",
      "🎯 TabPFN stacking for BlendProperty9...\n",
      "    Fold 1/5\n",
      "    Fold 2/5\n",
      "    Fold 3/5\n",
      "    Fold 4/5\n",
      "    Fold 5/5\n",
      "🎯 TabPFN stacking for BlendProperty10...\n",
      "    Fold 1/5\n",
      "    Fold 2/5\n",
      "    Fold 3/5\n",
      "    Fold 4/5\n",
      "    Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-23 02:57:50,740] A new study created in memory with name: no-name-cd8f5522-ae98-452c-ab7c-476ea950830f\n",
      "[I 2025-07-23 02:57:50,746] Trial 0 finished with value: 1.0672458799116427 and parameters: {'w_xgb': 0.7441962503772418, 'w_lgbm': 0.8345495198605164, 'w_mlp': 0.9820962408124294, 'w_tabpfn': 0.12927815301654044}. Best is trial 0 with value: 1.0672458799116427.\n",
      "[I 2025-07-23 02:57:50,749] Trial 1 finished with value: 1.0445995333613882 and parameters: {'w_xgb': 0.5715363862615984, 'w_lgbm': 0.7349567706425825, 'w_mlp': 0.2268260506946207, 'w_tabpfn': 0.8373104781254307}. Best is trial 1 with value: 1.0445995333613882.\n",
      "[I 2025-07-23 02:57:50,752] Trial 2 finished with value: 1.3186304317788138 and parameters: {'w_xgb': 0.7238414692076094, 'w_lgbm': 0.4992369648199598, 'w_mlp': 0.016416712708327896, 'w_tabpfn': 0.12446809388530355}. Best is trial 1 with value: 1.0445995333613882.\n",
      "[I 2025-07-23 02:57:50,753] Trial 3 finished with value: 0.9879936296500016 and parameters: {'w_xgb': 0.23181947796901703, 'w_lgbm': 0.29441478531638043, 'w_mlp': 0.4073635027731082, 'w_tabpfn': 0.47612151416330584}. Best is trial 3 with value: 0.9879936296500016.\n",
      "[I 2025-07-23 02:57:50,755] Trial 4 finished with value: 1.1726087619369037 and parameters: {'w_xgb': 0.0740192510593577, 'w_lgbm': 0.265545034232717, 'w_mlp': 0.6901272179832162, 'w_tabpfn': 0.3158510939782968}. Best is trial 3 with value: 0.9879936296500016.\n",
      "[I 2025-07-23 02:57:50,758] Trial 5 finished with value: 1.1680370869282553 and parameters: {'w_xgb': 0.9035251546128963, 'w_lgbm': 0.09910891886547712, 'w_mlp': 0.8532201589169488, 'w_tabpfn': 0.2513214143081044}. Best is trial 3 with value: 0.9879936296500016.\n",
      "[I 2025-07-23 02:57:50,763] Trial 6 finished with value: 0.9862695820377801 and parameters: {'w_xgb': 0.35697599909499966, 'w_lgbm': 0.7721952114308837, 'w_mlp': 0.28357680907812444, 'w_tabpfn': 0.9041656082978383}. Best is trial 6 with value: 0.9862695820377801.\n",
      "[I 2025-07-23 02:57:50,769] Trial 7 finished with value: 1.0264621746738025 and parameters: {'w_xgb': 0.19467150686091095, 'w_lgbm': 0.08155599511125089, 'w_mlp': 0.5112822464786644, 'w_tabpfn': 0.845932799260786}. Best is trial 6 with value: 0.9862695820377801.\n",
      "[I 2025-07-23 02:57:50,772] Trial 8 finished with value: 1.1500946733258783 and parameters: {'w_xgb': 0.9189993334219415, 'w_lgbm': 0.6825399133800598, 'w_mlp': 0.17404021611488074, 'w_tabpfn': 0.6412085609079612}. Best is trial 6 with value: 0.9862695820377801.\n",
      "[I 2025-07-23 02:57:50,775] Trial 9 finished with value: 1.0931083982160332 and parameters: {'w_xgb': 0.865519332789034, 'w_lgbm': 0.3391924933738212, 'w_mlp': 0.5947179318502838, 'w_tabpfn': 0.7888038233486347}. Best is trial 6 with value: 0.9862695820377801.\n",
      "[I 2025-07-23 02:57:50,793] Trial 10 finished with value: 0.989186540702832 and parameters: {'w_xgb': 0.40736534024483223, 'w_lgbm': 0.9593612702889937, 'w_mlp': 0.31952365326064047, 'w_tabpfn': 0.9590873267434208}. Best is trial 6 with value: 0.9862695820377801.\n",
      "[I 2025-07-23 02:57:50,811] Trial 11 finished with value: 1.0026237015751491 and parameters: {'w_xgb': 0.31693613498795215, 'w_lgbm': 0.5203413442523299, 'w_mlp': 0.3789518084184011, 'w_tabpfn': 0.4673989227676677}. Best is trial 6 with value: 0.9862695820377801.\n",
      "[I 2025-07-23 02:57:50,826] Trial 12 finished with value: 0.9807856004915468 and parameters: {'w_xgb': 0.26046609068156795, 'w_lgbm': 0.49284201885596407, 'w_mlp': 0.4080629110515558, 'w_tabpfn': 0.4967582110669911}. Best is trial 12 with value: 0.9807856004915468.\n",
      "[I 2025-07-23 02:57:50,842] Trial 13 finished with value: 1.0898244208142134 and parameters: {'w_xgb': 0.517868288707217, 'w_lgbm': 0.521526179000325, 'w_mlp': 0.07525476493635597, 'w_tabpfn': 0.6285130149414375}. Best is trial 12 with value: 0.9807856004915468.\n",
      "[I 2025-07-23 02:57:50,860] Trial 14 finished with value: 1.0396542628200414 and parameters: {'w_xgb': 0.0057036940119005175, 'w_lgbm': 0.6514580433504535, 'w_mlp': 0.28169209901004777, 'w_tabpfn': 0.629239904247324}. Best is trial 12 with value: 0.9807856004915468.\n",
      "[I 2025-07-23 02:57:50,873] Trial 15 finished with value: 1.0173827774197193 and parameters: {'w_xgb': 0.4036771107752025, 'w_lgbm': 0.9837387328780831, 'w_mlp': 0.4771661150004684, 'w_tabpfn': 0.29704462892035}. Best is trial 12 with value: 0.9807856004915468.\n",
      "[I 2025-07-23 02:57:50,894] Trial 16 finished with value: 0.9767388308016169 and parameters: {'w_xgb': 0.16629834314470426, 'w_lgbm': 0.7993390125726095, 'w_mlp': 0.1784345740957431, 'w_tabpfn': 0.41740175893232867}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:50,914] Trial 17 finished with value: 0.9846988678783666 and parameters: {'w_xgb': 0.1619243316605438, 'w_lgbm': 0.6081292524915289, 'w_mlp': 0.12558801951734, 'w_tabpfn': 0.39877302838277007}. Best is trial 16 with value: 0.9767388308016169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Level 2 MAPE Scores:\n",
      "  MLP: 1.546973\n",
      "  TabPFN: 0.988756\n",
      "\n",
      "🔍 Starting Level 3 optimization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-23 02:57:50,932] Trial 18 finished with value: 1.0952725930314742 and parameters: {'w_xgb': 0.10044703804480465, 'w_lgbm': 0.4021102909243912, 'w_mlp': 0.6670012471693011, 'w_tabpfn': 0.6109834210947006}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:50,949] Trial 19 finished with value: 0.9851685044084448 and parameters: {'w_xgb': 0.26414860717870886, 'w_lgbm': 0.8577773168620451, 'w_mlp': 0.49829576138450715, 'w_tabpfn': 0.7375815713095109}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:50,965] Trial 20 finished with value: 1.2517672346506958 and parameters: {'w_xgb': 0.6172530297765135, 'w_lgbm': 0.17140174752770082, 'w_mlp': 0.19485213466957596, 'w_tabpfn': 0.20522457756619977}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:50,981] Trial 21 finished with value: 0.979609190240781 and parameters: {'w_xgb': 0.14204998063580637, 'w_lgbm': 0.6188385649098682, 'w_mlp': 0.10837292529485903, 'w_tabpfn': 0.4005963876594411}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:50,995] Trial 22 finished with value: 0.989088109052985 and parameters: {'w_xgb': 0.0009429592190006719, 'w_lgbm': 0.5737390476814588, 'w_mlp': 0.01838519037284747, 'w_tabpfn': 0.3998512052763197}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,010] Trial 23 finished with value: 1.0358034315482478 and parameters: {'w_xgb': 0.12823790325047427, 'w_lgbm': 0.438382136898864, 'w_mlp': 0.11876595078340946, 'w_tabpfn': 0.03699933069877792}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,030] Trial 24 finished with value: 0.9878439354655624 and parameters: {'w_xgb': 0.302080677036009, 'w_lgbm': 0.8842305057229951, 'w_mlp': 0.354705502828327, 'w_tabpfn': 0.5314975971058772}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,046] Trial 25 finished with value: 1.067180563704362 and parameters: {'w_xgb': 0.45966395472336613, 'w_lgbm': 0.7467742950172724, 'w_mlp': 0.21046870737211887, 'w_tabpfn': 0.36992593680172003}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,064] Trial 26 finished with value: 0.9910278251546177 and parameters: {'w_xgb': 0.19787369996087048, 'w_lgbm': 0.6791416790628635, 'w_mlp': 0.08464658785390111, 'w_tabpfn': 0.5375940237251676}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,083] Trial 27 finished with value: 1.062955386221568 and parameters: {'w_xgb': 0.08347966326009038, 'w_lgbm': 0.4115396302231017, 'w_mlp': 0.43099079683089664, 'w_tabpfn': 0.4387495243658064}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,099] Trial 28 finished with value: 0.9913616918738107 and parameters: {'w_xgb': 0.2671533314799769, 'w_lgbm': 0.5948672523027738, 'w_mlp': 0.2550055707435426, 'w_tabpfn': 0.5433469166412307}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,116] Trial 29 finished with value: 1.1252691272823188 and parameters: {'w_xgb': 0.16051779363456312, 'w_lgbm': 0.8132065462228331, 'w_mlp': 0.9385474310953955, 'w_tabpfn': 0.19671900012988192}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,131] Trial 30 finished with value: 0.9899483204177455 and parameters: {'w_xgb': 0.0486610116733702, 'w_lgbm': 0.9220079912836123, 'w_mlp': 0.15234692069225106, 'w_tabpfn': 0.7212715639469207}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,149] Trial 31 finished with value: 0.990583514660833 and parameters: {'w_xgb': 0.16277453102944137, 'w_lgbm': 0.6117183955315587, 'w_mlp': 0.10728098026988893, 'w_tabpfn': 0.3777200862434721}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,166] Trial 32 finished with value: 1.0290617749443651 and parameters: {'w_xgb': 0.22127097180101507, 'w_lgbm': 0.7116628164070252, 'w_mlp': 0.05144459167767679, 'w_tabpfn': 0.3303048784321998}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,187] Trial 33 finished with value: 1.044934146645169 and parameters: {'w_xgb': 0.34025029235693094, 'w_lgbm': 0.48691660953231797, 'w_mlp': 0.16020285016956703, 'w_tabpfn': 0.4388087751517567}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,202] Trial 34 finished with value: 1.0261213123096489 and parameters: {'w_xgb': 0.14456775763110405, 'w_lgbm': 0.5709047967458241, 'w_mlp': 0.008384179743571862, 'w_tabpfn': 0.2521712473508102}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,218] Trial 35 finished with value: 0.9894635827192289 and parameters: {'w_xgb': 0.2512086470691114, 'w_lgbm': 0.7754387701561877, 'w_mlp': 0.2440683607218156, 'w_tabpfn': 0.486425522498235}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,235] Trial 36 finished with value: 1.0829925131283615 and parameters: {'w_xgb': 0.6618760510081726, 'w_lgbm': 0.6336973227541324, 'w_mlp': 0.3306139460758081, 'w_tabpfn': 0.5779190600992523}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,251] Trial 37 finished with value: 1.2017745868021812 and parameters: {'w_xgb': 0.053870169117618355, 'w_lgbm': 0.4594938597110726, 'w_mlp': 0.7569996546074642, 'w_tabpfn': 0.11890526650355893}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,270] Trial 38 finished with value: 1.0834030025449923 and parameters: {'w_xgb': 0.38496775125356864, 'w_lgbm': 0.3466253430567917, 'w_mlp': 0.1306997273663955, 'w_tabpfn': 0.4218164192491527}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,291] Trial 39 finished with value: 1.0259035402888892 and parameters: {'w_xgb': 0.4652681420254695, 'w_lgbm': 0.8079979636681622, 'w_mlp': 0.5714296326266614, 'w_tabpfn': 0.33614147930451077}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,308] Trial 40 finished with value: 1.1317779268519905 and parameters: {'w_xgb': 0.9997260228417433, 'w_lgbm': 0.5512112575154184, 'w_mlp': 0.4313552304657121, 'w_tabpfn': 0.6940687722494007}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,326] Trial 41 finished with value: 1.0057227932863435 and parameters: {'w_xgb': 0.2771810681497857, 'w_lgbm': 0.8232226470191677, 'w_mlp': 0.5891896638658372, 'w_tabpfn': 0.5009922637120227}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,346] Trial 42 finished with value: 0.9990188674764626 and parameters: {'w_xgb': 0.2147871450600807, 'w_lgbm': 0.8649799322829148, 'w_mlp': 0.5058889157028134, 'w_tabpfn': 0.763427849226182}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,363] Trial 43 finished with value: 1.0316868297273942 and parameters: {'w_xgb': 0.1760976098141684, 'w_lgbm': 0.7267318395094764, 'w_mlp': 0.6476725063931941, 'w_tabpfn': 0.8817412442090593}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,382] Trial 44 finished with value: 1.0924432688116825 and parameters: {'w_xgb': 0.1082893309335351, 'w_lgbm': 0.9051146869474835, 'w_mlp': 0.7501556652899297, 'w_tabpfn': 0.3637080480494381}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,399] Trial 45 finished with value: 1.0158429752029323 and parameters: {'w_xgb': 0.29873697399843757, 'w_lgbm': 0.6835920214481848, 'w_mlp': 0.30601704854285183, 'w_tabpfn': 0.3013753647451958}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,415] Trial 46 finished with value: 1.005231038338285 and parameters: {'w_xgb': 0.23818451561774806, 'w_lgbm': 0.6395724522149936, 'w_mlp': 0.5480436148040312, 'w_tabpfn': 0.6741934338398129}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,433] Trial 47 finished with value: 1.0055856389632218 and parameters: {'w_xgb': 0.35459624095331777, 'w_lgbm': 0.7654602853664201, 'w_mlp': 0.05053854621328546, 'w_tabpfn': 0.9907427184770911}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,450] Trial 48 finished with value: 1.0530833862198943 and parameters: {'w_xgb': 0.0388222695818652, 'w_lgbm': 0.8623171555723543, 'w_mlp': 0.40144460745078625, 'w_tabpfn': 0.469484942749375}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,469] Trial 49 finished with value: 1.2256132947268514 and parameters: {'w_xgb': 0.7555171185610523, 'w_lgbm': 0.02682043274490875, 'w_mlp': 0.211342682401656, 'w_tabpfn': 0.5104936113335348}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,487] Trial 50 finished with value: 1.0474229968692357 and parameters: {'w_xgb': 0.12330366496535541, 'w_lgbm': 0.3510400598373745, 'w_mlp': 0.4750877281162447, 'w_tabpfn': 0.5748162659862313}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,504] Trial 51 finished with value: 0.9793532879360145 and parameters: {'w_xgb': 0.33728335120800745, 'w_lgbm': 0.9516497169541946, 'w_mlp': 0.28527889086318553, 'w_tabpfn': 0.9221427040306125}. Best is trial 16 with value: 0.9767388308016169.\n",
      "[I 2025-07-23 02:57:51,520] Trial 52 finished with value: 0.9641123082425173 and parameters: {'w_xgb': 0.20295293146747978, 'w_lgbm': 0.9488392526305888, 'w_mlp': 0.28858862709478894, 'w_tabpfn': 0.810368483027663}. Best is trial 52 with value: 0.9641123082425173.\n",
      "[I 2025-07-23 02:57:51,539] Trial 53 finished with value: 0.9623033313478843 and parameters: {'w_xgb': 0.19627633750197293, 'w_lgbm': 0.9076601141886338, 'w_mlp': 0.273248167221555, 'w_tabpfn': 0.8290256269154966}. Best is trial 53 with value: 0.9623033313478843.\n",
      "[I 2025-07-23 02:57:51,558] Trial 54 finished with value: 0.9632422489893038 and parameters: {'w_xgb': 0.1974636131572931, 'w_lgbm': 0.9918946633215084, 'w_mlp': 0.2708455169969714, 'w_tabpfn': 0.8150820866829311}. Best is trial 53 with value: 0.9623033313478843.\n",
      "[I 2025-07-23 02:57:51,573] Trial 55 finished with value: 0.9632229415553921 and parameters: {'w_xgb': 0.19585827605552375, 'w_lgbm': 0.941409431346207, 'w_mlp': 0.2739909858566504, 'w_tabpfn': 0.8213004215856741}. Best is trial 53 with value: 0.9623033313478843.\n",
      "[I 2025-07-23 02:57:51,593] Trial 56 finished with value: 0.9653540647631427 and parameters: {'w_xgb': 0.19569717454998806, 'w_lgbm': 0.9947584434419694, 'w_mlp': 0.27893589965303967, 'w_tabpfn': 0.8011504327124025}. Best is trial 53 with value: 0.9623033313478843.\n",
      "[I 2025-07-23 02:57:51,609] Trial 57 finished with value: 0.9583071789139783 and parameters: {'w_xgb': 0.21103262774939624, 'w_lgbm': 0.9956621331249628, 'w_mlp': 0.25920780239827057, 'w_tabpfn': 0.823623199659455}. Best is trial 57 with value: 0.9583071789139783.\n",
      "[I 2025-07-23 02:57:51,628] Trial 58 finished with value: 0.9758413985458343 and parameters: {'w_xgb': 0.19964598072088213, 'w_lgbm': 0.9982466950746857, 'w_mlp': 0.34940895742772793, 'w_tabpfn': 0.8212408662542856}. Best is trial 57 with value: 0.9583071789139783.\n",
      "[I 2025-07-23 02:57:51,646] Trial 59 finished with value: 0.9884607851632436 and parameters: {'w_xgb': 0.093345851842526, 'w_lgbm': 0.9496743039905958, 'w_mlp': 0.24276046122252803, 'w_tabpfn': 0.8150727143168348}. Best is trial 57 with value: 0.9583071789139783.\n",
      "[I 2025-07-23 02:57:51,667] Trial 60 finished with value: 0.9763685857725916 and parameters: {'w_xgb': 0.3083784529309722, 'w_lgbm': 0.9704876525963796, 'w_mlp': 0.27985342660200535, 'w_tabpfn': 0.8622287973253587}. Best is trial 57 with value: 0.9583071789139783.\n",
      "[I 2025-07-23 02:57:51,684] Trial 61 finished with value: 0.9760015577463396 and parameters: {'w_xgb': 0.20407953959459796, 'w_lgbm': 0.9881600659421002, 'w_mlp': 0.3580402382104467, 'w_tabpfn': 0.8217945475449051}. Best is trial 57 with value: 0.9583071789139783.\n",
      "[I 2025-07-23 02:57:51,703] Trial 62 finished with value: 0.9728533187809913 and parameters: {'w_xgb': 0.19178018245705508, 'w_lgbm': 0.9915335566981371, 'w_mlp': 0.3155662824322958, 'w_tabpfn': 0.7859330191637832}. Best is trial 57 with value: 0.9583071789139783.\n",
      "[I 2025-07-23 02:57:51,719] Trial 63 finished with value: 0.9611123599521433 and parameters: {'w_xgb': 0.2370616399227437, 'w_lgbm': 0.9211755687841852, 'w_mlp': 0.3179479716048691, 'w_tabpfn': 0.7869479014575514}. Best is trial 57 with value: 0.9583071789139783.\n",
      "[I 2025-07-23 02:57:51,735] Trial 64 finished with value: 0.9582358803692801 and parameters: {'w_xgb': 0.23521396740554545, 'w_lgbm': 0.9261867848792217, 'w_mlp': 0.2681136782834351, 'w_tabpfn': 0.9374189472182755}. Best is trial 64 with value: 0.9582358803692801.\n",
      "[I 2025-07-23 02:57:51,753] Trial 65 finished with value: 0.9628548220165779 and parameters: {'w_xgb': 0.24222222625932893, 'w_lgbm': 0.9268635832542306, 'w_mlp': 0.22545859377931368, 'w_tabpfn': 0.9395383004223989}. Best is trial 64 with value: 0.9582358803692801.\n",
      "[I 2025-07-23 02:57:51,769] Trial 66 finished with value: 0.9651661210756413 and parameters: {'w_xgb': 0.2424137204101421, 'w_lgbm': 0.9171033530502233, 'w_mlp': 0.1969961406053788, 'w_tabpfn': 0.9392940755478776}. Best is trial 64 with value: 0.9582358803692801.\n",
      "[I 2025-07-23 02:57:51,791] Trial 67 finished with value: 0.9919283229522 and parameters: {'w_xgb': 0.3946090341459574, 'w_lgbm': 0.8936574839575148, 'w_mlp': 0.23443432755762086, 'w_tabpfn': 0.9992816623092893}. Best is trial 64 with value: 0.9582358803692801.\n",
      "[I 2025-07-23 02:57:51,809] Trial 68 finished with value: 0.9765776904309181 and parameters: {'w_xgb': 0.2783708774990814, 'w_lgbm': 0.9338307715165639, 'w_mlp': 0.1814339971272767, 'w_tabpfn': 0.8963034561296148}. Best is trial 64 with value: 0.9582358803692801.\n",
      "[I 2025-07-23 02:57:51,826] Trial 69 finished with value: 1.0228191974806937 and parameters: {'w_xgb': 0.5639155488316495, 'w_lgbm': 0.8396170945987786, 'w_mlp': 0.3819083185134331, 'w_tabpfn': 0.8614974337466802}. Best is trial 64 with value: 0.9582358803692801.\n",
      "[I 2025-07-23 02:57:51,845] Trial 70 finished with value: 0.9722641359517123 and parameters: {'w_xgb': 0.14535967246517345, 'w_lgbm': 0.8845262656199269, 'w_mlp': 0.25919932017516445, 'w_tabpfn': 0.9578115097175994}. Best is trial 64 with value: 0.9582358803692801.\n",
      "[I 2025-07-23 02:57:51,858] Trial 71 finished with value: 0.9635924227931536 and parameters: {'w_xgb': 0.2308081532455143, 'w_lgbm': 0.9307695920106585, 'w_mlp': 0.3256414773555702, 'w_tabpfn': 0.7602474515795894}. Best is trial 64 with value: 0.9582358803692801.\n",
      "[I 2025-07-23 02:57:51,883] Trial 72 finished with value: 0.9646762828062452 and parameters: {'w_xgb': 0.23363788697805118, 'w_lgbm': 0.9109538914575263, 'w_mlp': 0.33433116120789214, 'w_tabpfn': 0.7253225376011531}. Best is trial 64 with value: 0.9582358803692801.\n",
      "[I 2025-07-23 02:57:51,900] Trial 73 finished with value: 0.9828488844766442 and parameters: {'w_xgb': 0.2891358788838666, 'w_lgbm': 0.8490274361608287, 'w_mlp': 0.2220600295914786, 'w_tabpfn': 0.7604475673671033}. Best is trial 64 with value: 0.9582358803692801.\n",
      "[I 2025-07-23 02:57:51,913] Trial 74 finished with value: 0.9744873396122765 and parameters: {'w_xgb': 0.3274310296358367, 'w_lgbm': 0.96520635500992, 'w_mlp': 0.37469443168835936, 'w_tabpfn': 0.8438503155001603}. Best is trial 64 with value: 0.9582358803692801.\n",
      "[I 2025-07-23 02:57:51,935] Trial 75 finished with value: 0.9715464068235173 and parameters: {'w_xgb': 0.2501618795054267, 'w_lgbm': 0.9266616444565444, 'w_mlp': 0.16042938313736774, 'w_tabpfn': 0.9080416994065423}. Best is trial 64 with value: 0.9582358803692801.\n",
      "[I 2025-07-23 02:57:51,952] Trial 76 finished with value: 0.9949864609651297 and parameters: {'w_xgb': 0.37666902767798427, 'w_lgbm': 0.8739343053017149, 'w_mlp': 0.3071369497689257, 'w_tabpfn': 0.7688761085782224}. Best is trial 64 with value: 0.9582358803692801.\n",
      "[I 2025-07-23 02:57:51,970] Trial 77 finished with value: 1.0029798463400277 and parameters: {'w_xgb': 0.42848698973462834, 'w_lgbm': 0.9369538668726075, 'w_mlp': 0.2658834847458284, 'w_tabpfn': 0.8653437292792823}. Best is trial 64 with value: 0.9582358803692801.\n",
      "[I 2025-07-23 02:57:51,990] Trial 78 finished with value: 1.004007171083855 and parameters: {'w_xgb': 0.17229028261507845, 'w_lgbm': 0.7899091262514206, 'w_mlp': 0.447120006063192, 'w_tabpfn': 0.6848622186303321}. Best is trial 64 with value: 0.9582358803692801.\n",
      "[I 2025-07-23 02:57:52,008] Trial 79 finished with value: 0.9774830569904374 and parameters: {'w_xgb': 0.10958778973915184, 'w_lgbm': 0.893448315384714, 'w_mlp': 0.2266093133866559, 'w_tabpfn': 0.9442089878210396}. Best is trial 64 with value: 0.9582358803692801.\n",
      "[I 2025-07-23 02:57:52,030] Trial 80 finished with value: 1.0166452903597505 and parameters: {'w_xgb': 0.0794774333246421, 'w_lgbm': 0.9749667900539889, 'w_mlp': 0.40210963187114157, 'w_tabpfn': 0.8862932887766914}. Best is trial 64 with value: 0.9582358803692801.\n",
      "[I 2025-07-23 02:57:52,049] Trial 81 finished with value: 0.96342247059815 and parameters: {'w_xgb': 0.2220982264754873, 'w_lgbm': 0.949988193502608, 'w_mlp': 0.30874467988797144, 'w_tabpfn': 0.7447143846059996}. Best is trial 64 with value: 0.9582358803692801.\n",
      "[I 2025-07-23 02:57:52,068] Trial 82 finished with value: 0.9698523849912446 and parameters: {'w_xgb': 0.22372859112171742, 'w_lgbm': 0.9585820509499706, 'w_mlp': 0.1991761722109071, 'w_tabpfn': 0.746452436479042}. Best is trial 64 with value: 0.9582358803692801.\n",
      "[I 2025-07-23 02:57:52,089] Trial 83 finished with value: 0.983923243773555 and parameters: {'w_xgb': 0.2726089639507356, 'w_lgbm': 0.2513795861828752, 'w_mlp': 0.32543996385575424, 'w_tabpfn': 0.7166277369914671}. Best is trial 64 with value: 0.9582358803692801.\n",
      "[I 2025-07-23 02:57:52,108] Trial 84 finished with value: 0.9831560666925748 and parameters: {'w_xgb': 0.14326705240993837, 'w_lgbm': 0.827074168245395, 'w_mlp': 0.30192073982571216, 'w_tabpfn': 0.7807637333105261}. Best is trial 64 with value: 0.9582358803692801.\n",
      "[I 2025-07-23 02:57:52,123] Trial 85 finished with value: 0.9771488010270545 and parameters: {'w_xgb': 0.31478869680900384, 'w_lgbm': 0.9135049735547699, 'w_mlp': 0.25543527254768406, 'w_tabpfn': 0.9203151219356827}. Best is trial 64 with value: 0.9582358803692801.\n",
      "[I 2025-07-23 02:57:52,146] Trial 86 finished with value: 0.9846239877681832 and parameters: {'w_xgb': 0.1798688006302933, 'w_lgbm': 0.868021423824273, 'w_mlp': 0.35436886797283007, 'w_tabpfn': 0.6674246651618339}. Best is trial 64 with value: 0.9582358803692801.\n",
      "[I 2025-07-23 02:57:52,162] Trial 87 finished with value: 0.9761562793383382 and parameters: {'w_xgb': 0.26104344192359796, 'w_lgbm': 0.9344323016660989, 'w_mlp': 0.17403412107390853, 'w_tabpfn': 0.8405874663501551}. Best is trial 64 with value: 0.9582358803692801.\n",
      "[I 2025-07-23 02:57:52,180] Trial 88 finished with value: 0.9681509396712003 and parameters: {'w_xgb': 0.22710963711603382, 'w_lgbm': 0.8983495171766033, 'w_mlp': 0.3365134903334616, 'w_tabpfn': 0.6468137972255988}. Best is trial 64 with value: 0.9582358803692801.\n",
      "[I 2025-07-23 02:57:52,198] Trial 89 finished with value: 0.9582326586598123 and parameters: {'w_xgb': 0.1320624945513414, 'w_lgbm': 0.970729743675825, 'w_mlp': 0.14543385005437917, 'w_tabpfn': 0.9743300256151771}. Best is trial 89 with value: 0.9582326586598123.\n",
      "[I 2025-07-23 02:57:52,213] Trial 90 finished with value: 0.9503130636813705 and parameters: {'w_xgb': 0.15688547116784732, 'w_lgbm': 0.9728202432791374, 'w_mlp': 0.13839431692926124, 'w_tabpfn': 0.9735670577313329}. Best is trial 90 with value: 0.9503130636813705.\n",
      "[I 2025-07-23 02:57:52,234] Trial 91 finished with value: 0.9906578371937902 and parameters: {'w_xgb': 0.026512135561595096, 'w_lgbm': 0.969342194336916, 'w_mlp': 0.1438255705757578, 'w_tabpfn': 0.9638033054828817}. Best is trial 90 with value: 0.9503130636813705.\n",
      "[I 2025-07-23 02:57:52,252] Trial 92 finished with value: 0.9520373841257509 and parameters: {'w_xgb': 0.13195875888835132, 'w_lgbm': 0.9944387166441377, 'w_mlp': 0.0669446559930652, 'w_tabpfn': 0.9753715446560611}. Best is trial 90 with value: 0.9503130636813705.\n",
      "[I 2025-07-23 02:57:52,267] Trial 93 finished with value: 0.9520178460698853 and parameters: {'w_xgb': 0.12048523847618198, 'w_lgbm': 0.9960370480407461, 'w_mlp': 0.0800271302743746, 'w_tabpfn': 0.975751391025195}. Best is trial 90 with value: 0.9503130636813705.\n",
      "[I 2025-07-23 02:57:52,288] Trial 94 finished with value: 0.9505862726335483 and parameters: {'w_xgb': 0.11896445372371788, 'w_lgbm': 0.9721580804771941, 'w_mlp': 0.07193764326589384, 'w_tabpfn': 0.9772083750724719}. Best is trial 90 with value: 0.9503130636813705.\n",
      "[I 2025-07-23 02:57:52,307] Trial 95 finished with value: 0.966085629903608 and parameters: {'w_xgb': 0.06882310896159843, 'w_lgbm': 0.9995848765797014, 'w_mlp': 0.07018881988623907, 'w_tabpfn': 0.9718592826507212}. Best is trial 90 with value: 0.9503130636813705.\n",
      "[I 2025-07-23 02:57:52,324] Trial 96 finished with value: 0.9543683348620989 and parameters: {'w_xgb': 0.12705882697913257, 'w_lgbm': 0.9678433373656198, 'w_mlp': 0.033113740931719815, 'w_tabpfn': 0.9796367976030167}. Best is trial 90 with value: 0.9503130636813705.\n",
      "[I 2025-07-23 02:57:52,343] Trial 97 finished with value: 0.9511803926868833 and parameters: {'w_xgb': 0.11680842403269906, 'w_lgbm': 0.974304483762826, 'w_mlp': 0.03990345515994387, 'w_tabpfn': 0.9807002334758254}. Best is trial 90 with value: 0.9503130636813705.\n",
      "[I 2025-07-23 02:57:52,362] Trial 98 finished with value: 0.9530624744242179 and parameters: {'w_xgb': 0.12196674786856034, 'w_lgbm': 0.9682244033081846, 'w_mlp': 0.03368290981690414, 'w_tabpfn': 0.981400582202695}. Best is trial 90 with value: 0.9503130636813705.\n",
      "[I 2025-07-23 02:57:52,381] Trial 99 finished with value: 0.9530814921386039 and parameters: {'w_xgb': 0.12236407364600982, 'w_lgbm': 0.9677097958249442, 'w_mlp': 0.0333364513942903, 'w_tabpfn': 0.98463345933546}. Best is trial 90 with value: 0.9503130636813705.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Best MAPE: 0.950313\n",
      "🎯 Best weights:\n",
      "  w_xgb: 0.1569\n",
      "  w_lgbm: 0.9728\n",
      "  w_mlp: 0.1384\n",
      "  w_tabpfn: 0.9736\n",
      "\n",
      "📊 Normalized weights:\n",
      "  w_xgb: 0.0700\n",
      "  w_lgbm: 0.4340\n",
      "  w_mlp: 0.0617\n",
      "  w_tabpfn: 0.4343\n",
      "\n",
      "🎉 Final ensemble MAPE: 0.950313\n",
      "\n",
      "📊 Individual target MAPE scores:\n",
      "  BlendProperty1: 0.954313\n",
      "  BlendProperty2: 0.899590\n",
      "  BlendProperty3: 1.358098\n",
      "  BlendProperty4: 0.957680\n",
      "  BlendProperty5: 0.114740\n",
      "  BlendProperty6: 0.823275\n",
      "  BlendProperty7: 1.064241\n",
      "  BlendProperty8: 0.960809\n",
      "  BlendProperty9: 1.672063\n",
      "  BlendProperty10: 0.698321\n",
      "\n",
      "💾 Submission file saved as 'submission_optimized_ensemble.csv'\n",
      "\n",
      "🎯 Ensemble Summary:\n",
      "  Level 1: 14 base models\n",
      "  Level 2: MLP + TabPFN stacking\n",
      "  Level 3: Optimized weighted ensemble\n",
      "  Final MAPE: 0.950313\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, BayesianRidge, HuberRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, GradientBoostingRegressor, BaggingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import torch\n",
    "from tabpfn import TabPFNRegressor\n",
    "\n",
    "print(\"Loading data...\")\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "X = train.drop([f'BlendProperty{i}' for i in range(1, 11)], axis=1)\n",
    "y = train[[f'BlendProperty{i}' for i in range(1, 11)]]\n",
    "X_test = test.drop(['ID'], axis=1)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"🚀 Starting Level 1 training...\")\n",
    "model_names = [\n",
    "    'Ridge', 'Lasso', 'ElasticNet', 'BayesianRidge', 'Huber',\n",
    "    'RandomForest', 'ExtraTrees', 'AdaBoost', 'GradientBoost', 'Bagging',\n",
    "    'KNN', 'SVR', 'XGB', 'LGBM'\n",
    "]\n",
    "models_oof = {name: np.zeros(y.shape) for name in model_names}\n",
    "models_test = {name: np.zeros((X_test.shape[0], y.shape[1])) for name in model_names}\n",
    "\n",
    "for t in range(y.shape[1]):\n",
    "    print(f\"🎯 Training for target BlendProperty{t+1}...\")\n",
    "    for fold, (tr_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"  Fold {fold+1}/5\")\n",
    "        X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[tr_idx, t], y.iloc[val_idx, t]\n",
    "\n",
    "        # Ridge\n",
    "        ridge = Ridge(alpha=1.0)\n",
    "        ridge.fit(X_tr, y_tr)\n",
    "        models_oof['Ridge'][val_idx, t] = ridge.predict(X_val)\n",
    "        models_test['Ridge'][:, t] += ridge.predict(X_test) / kf.n_splits\n",
    "\n",
    "        # Lasso\n",
    "        lasso = Lasso(alpha=0.1)\n",
    "        lasso.fit(X_tr, y_tr)\n",
    "        models_oof['Lasso'][val_idx, t] = lasso.predict(X_val)\n",
    "        models_test['Lasso'][:, t] += lasso.predict(X_test) / kf.n_splits\n",
    "\n",
    "        # ElasticNet\n",
    "        elastic = ElasticNet(alpha=0.1)\n",
    "        elastic.fit(X_tr, y_tr)\n",
    "        models_oof['ElasticNet'][val_idx, t] = elastic.predict(X_val)\n",
    "        models_test['ElasticNet'][:, t] += elastic.predict(X_test) / kf.n_splits\n",
    "\n",
    "        # BayesianRidge\n",
    "        bayesian = BayesianRidge()\n",
    "        bayesian.fit(X_tr, y_tr)\n",
    "        models_oof['BayesianRidge'][val_idx, t] = bayesian.predict(X_val)\n",
    "        models_test['BayesianRidge'][:, t] += bayesian.predict(X_test) / kf.n_splits\n",
    "\n",
    "        # Huber\n",
    "        huber = HuberRegressor()\n",
    "        huber.fit(X_tr, y_tr)\n",
    "        models_oof['Huber'][val_idx, t] = huber.predict(X_val)\n",
    "        models_test['Huber'][:, t] += huber.predict(X_test) / kf.n_splits\n",
    "\n",
    "        # RandomForest\n",
    "        rf = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "        rf.fit(X_tr, y_tr)\n",
    "        models_oof['RandomForest'][val_idx, t] = rf.predict(X_val)\n",
    "        models_test['RandomForest'][:, t] += rf.predict(X_test) / kf.n_splits\n",
    "\n",
    "        # ExtraTrees\n",
    "        et = ExtraTreesRegressor(n_estimators=50, random_state=42)\n",
    "        et.fit(X_tr, y_tr)\n",
    "        models_oof['ExtraTrees'][val_idx, t] = et.predict(X_val)\n",
    "        models_test['ExtraTrees'][:, t] += et.predict(X_test) / kf.n_splits\n",
    "\n",
    "        # AdaBoost\n",
    "        ada = AdaBoostRegressor(random_state=42)\n",
    "        ada.fit(X_tr, y_tr)\n",
    "        models_oof['AdaBoost'][val_idx, t] = ada.predict(X_val)\n",
    "        models_test['AdaBoost'][:, t] += ada.predict(X_test) / kf.n_splits\n",
    "\n",
    "        # GradientBoosting\n",
    "        gb = GradientBoostingRegressor(random_state=42)\n",
    "        gb.fit(X_tr, y_tr)\n",
    "        models_oof['GradientBoost'][val_idx, t] = gb.predict(X_val)\n",
    "        models_test['GradientBoost'][:, t] += gb.predict(X_test) / kf.n_splits\n",
    "\n",
    "        # Bagging\n",
    "        bag = BaggingRegressor(random_state=42)\n",
    "        bag.fit(X_tr, y_tr)\n",
    "        models_oof['Bagging'][val_idx, t] = bag.predict(X_val)\n",
    "        models_test['Bagging'][:, t] += bag.predict(X_test) / kf.n_splits\n",
    "\n",
    "        # KNN\n",
    "        knn = KNeighborsRegressor()\n",
    "        knn.fit(X_tr, y_tr)\n",
    "        models_oof['KNN'][val_idx, t] = knn.predict(X_val)\n",
    "        models_test['KNN'][:, t] += knn.predict(X_test) / kf.n_splits\n",
    "\n",
    "        # SVR\n",
    "        svr = SVR()\n",
    "        svr.fit(X_tr, y_tr)\n",
    "        models_oof['SVR'][val_idx, t] = svr.predict(X_val)\n",
    "        models_test['SVR'][:, t] += svr.predict(X_test) / kf.n_splits\n",
    "\n",
    "        # XGBoost\n",
    "        xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "        xgb_model.fit(X_tr, y_tr)\n",
    "        models_oof['XGB'][val_idx, t] = xgb_model.predict(X_val)\n",
    "        models_test['XGB'][:, t] += xgb_model.predict(X_test) / kf.n_splits\n",
    "\n",
    "        # LightGBM\n",
    "        lgb_model = lgb.LGBMRegressor(random_state=42, verbose=-1)\n",
    "        lgb_model.fit(X_tr, y_tr)\n",
    "        models_oof['LGBM'][val_idx, t] = lgb_model.predict(X_val)\n",
    "        models_test['LGBM'][:, t] += lgb_model.predict(X_test) / kf.n_splits\n",
    "\n",
    "print(\"\\n📊 Level 1 MAPE Scores:\")\n",
    "for name in model_names:\n",
    "    mape = mean_absolute_percentage_error(y, models_oof[name])\n",
    "    print(f\"  {name}: {mape:.6f}\")\n",
    "\n",
    "print(\"\\n🔄 Stacking Level 1 outputs...\")\n",
    "stack_X = np.concatenate([models_oof[name] for name in model_names], axis=1)\n",
    "stack_X_test = np.concatenate([models_test[name] for name in model_names], axis=1)\n",
    "\n",
    "print(\"\\n🚀 Starting Level 2 stacking (MLP + TabPFN)...\")\n",
    "\n",
    "# MLP Stacking\n",
    "mlp_oof = np.zeros(y.shape)\n",
    "mlp_test = np.zeros((X_test.shape[0], y.shape[1]))\n",
    "\n",
    "for t in range(y.shape[1]):\n",
    "    print(f\"🧠 MLP stacking for BlendProperty{t+1}...\")\n",
    "    for fold, (tr_idx, val_idx) in enumerate(kf.split(stack_X)):\n",
    "        print(f\"    Fold {fold+1}/5\")\n",
    "        X_tr, X_val = stack_X[tr_idx], stack_X[val_idx]\n",
    "        y_tr, y_val = y.iloc[tr_idx, t], y.iloc[val_idx, t]\n",
    "\n",
    "        mlp = MLPRegressor(hidden_layer_sizes=(512, 256, 128), activation='relu', max_iter=500, random_state=42)\n",
    "        mlp.fit(X_tr, y_tr)\n",
    "        mlp_oof[val_idx, t] = mlp.predict(X_val)\n",
    "        mlp_test[:, t] += mlp.predict(stack_X_test) / kf.n_splits\n",
    "\n",
    "# TabPFN Stacking\n",
    "print(\"\\n🔥 TabPFN stacking...\")\n",
    "tabpfn_oof = np.zeros(y.shape)\n",
    "tabpfn_test = np.zeros((X_test.shape[0], y.shape[1]))\n",
    "\n",
    "for t in range(y.shape[1]):\n",
    "    print(f\"🎯 TabPFN stacking for BlendProperty{t+1}...\")\n",
    "    for fold, (tr_idx, val_idx) in enumerate(kf.split(stack_X)):\n",
    "        print(f\"    Fold {fold+1}/5\")\n",
    "        X_tr, X_val = stack_X[tr_idx], stack_X[val_idx]\n",
    "        y_tr, y_val = y.iloc[tr_idx, t], y.iloc[val_idx, t]\n",
    "\n",
    "        # Initialize TabPFN\n",
    "        tabpfn = TabPFNRegressor(device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        tabpfn.fit(X_tr, y_tr.values)\n",
    "        \n",
    "        tabpfn_oof[val_idx, t] = tabpfn.predict(X_val)\n",
    "        tabpfn_test[:, t] += tabpfn.predict(stack_X_test) / kf.n_splits\n",
    "\n",
    "print(\"\\n📊 Level 2 MAPE Scores:\")\n",
    "mlp_mape = mean_absolute_percentage_error(y, mlp_oof)\n",
    "tabpfn_mape = mean_absolute_percentage_error(y, tabpfn_oof)\n",
    "print(f\"  MLP: {mlp_mape:.6f}\")\n",
    "print(f\"  TabPFN: {tabpfn_mape:.6f}\")\n",
    "\n",
    "print(\"\\n🔍 Starting Level 3 optimization...\")\n",
    "\n",
    "# Prepare Level 3 inputs\n",
    "level3_oof = np.concatenate([\n",
    "    models_oof['XGB'], \n",
    "    models_oof['LGBM'], \n",
    "    mlp_oof, \n",
    "    tabpfn_oof\n",
    "], axis=1)\n",
    "\n",
    "level3_test = np.concatenate([\n",
    "    models_test['XGB'], \n",
    "    models_test['LGBM'], \n",
    "    mlp_test, \n",
    "    tabpfn_test\n",
    "], axis=1)\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest weights for each component\n",
    "    w_xgb = trial.suggest_float('w_xgb', 0.0, 1.0)\n",
    "    w_lgbm = trial.suggest_float('w_lgbm', 0.0, 1.0) \n",
    "    w_mlp = trial.suggest_float('w_mlp', 0.0, 1.0)\n",
    "    w_tabpfn = trial.suggest_float('w_tabpfn', 0.0, 1.0)\n",
    "    \n",
    "    # Normalize weights\n",
    "    total_weight = w_xgb + w_lgbm + w_mlp + w_tabpfn\n",
    "    if total_weight == 0:\n",
    "        return float('inf')\n",
    "    \n",
    "    w_xgb /= total_weight\n",
    "    w_lgbm /= total_weight\n",
    "    w_mlp /= total_weight\n",
    "    w_tabpfn /= total_weight\n",
    "    \n",
    "    # Create weighted ensemble\n",
    "    ensemble_pred = (w_xgb * models_oof['XGB'] + \n",
    "                    w_lgbm * models_oof['LGBM'] + \n",
    "                    w_mlp * mlp_oof + \n",
    "                    w_tabpfn * tabpfn_oof)\n",
    "    \n",
    "    # Calculate MAPE\n",
    "    mape = mean_absolute_percentage_error(y, ensemble_pred)\n",
    "    return mape\n",
    "\n",
    "# Optimize weights\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(f\"\\n✅ Best MAPE: {study.best_value:.6f}\")\n",
    "print(\"🎯 Best weights:\")\n",
    "best_params = study.best_params\n",
    "for param, value in best_params.items():\n",
    "    print(f\"  {param}: {value:.4f}\")\n",
    "\n",
    "# Normalize best weights\n",
    "total_weight = sum(best_params.values())\n",
    "normalized_weights = {k: v/total_weight for k, v in best_params.items()}\n",
    "\n",
    "print(\"\\n📊 Normalized weights:\")\n",
    "for param, value in normalized_weights.items():\n",
    "    print(f\"  {param}: {value:.4f}\")\n",
    "\n",
    "# Create final ensemble predictions\n",
    "final_test = (normalized_weights['w_xgb'] * models_test['XGB'] + \n",
    "              normalized_weights['w_lgbm'] * models_test['LGBM'] + \n",
    "              normalized_weights['w_mlp'] * mlp_test + \n",
    "              normalized_weights['w_tabpfn'] * tabpfn_test)\n",
    "\n",
    "# Final validation score\n",
    "final_oof = (normalized_weights['w_xgb'] * models_oof['XGB'] + \n",
    "             normalized_weights['w_lgbm'] * models_oof['LGBM'] + \n",
    "             normalized_weights['w_mlp'] * mlp_oof + \n",
    "             normalized_weights['w_tabpfn'] * tabpfn_oof)\n",
    "\n",
    "final_mape = mean_absolute_percentage_error(y, final_oof)\n",
    "print(f\"\\n🎉 Final ensemble MAPE: {final_mape:.6f}\")\n",
    "\n",
    "print(\"\\n📊 Individual target MAPE scores:\")\n",
    "for i in range(y.shape[1]):\n",
    "    target_mape = mean_absolute_percentage_error(y.iloc[:, i], final_oof[:, i])\n",
    "    print(f\"  BlendProperty{i+1}: {target_mape:.6f}\")\n",
    "\n",
    "# Save submission\n",
    "submission = pd.DataFrame(final_test, columns=[f'BlendProperty{i}' for i in range(1, 11)])\n",
    "submission.insert(0, 'ID', test['ID'])\n",
    "submission.to_csv(\"submission_optimized_ensemble.csv\", index=False)\n",
    "print(\"\\n💾 Submission file saved as 'submission_optimized_ensemble.csv'\")\n",
    "\n",
    "print(\"\\n🎯 Ensemble Summary:\")\n",
    "print(f\"  Level 1: {len(model_names)} base models\")\n",
    "print(f\"  Level 2: MLP + TabPFN stacking\") \n",
    "print(f\"  Level 3: Optimized weighted ensemble\")\n",
    "print(f\"  Final MAPE: {final_mape:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4885dba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting TabPFN multi-output regression...\n",
      "\n",
      "🎯 Training for target: BlendProperty1\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "\n",
      "🎯 Training for target: BlendProperty2\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "\n",
      "🎯 Training for target: BlendProperty3\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "\n",
      "🎯 Training for target: BlendProperty4\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "\n",
      "🎯 Training for target: BlendProperty5\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "\n",
      "🎯 Training for target: BlendProperty6\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "\n",
      "🎯 Training for target: BlendProperty7\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "\n",
      "🎯 Training for target: BlendProperty8\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "\n",
      "🎯 Training for target: BlendProperty9\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "\n",
      "🎯 Training for target: BlendProperty10\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "\n",
      "📊 MAPE Scores:\n",
      "✅ Overall MAPE: 0.507453\n",
      "  MAPE for BlendProperty1: 0.953927\n",
      "  MAPE for BlendProperty2: 0.272068\n",
      "  MAPE for BlendProperty3: 0.672616\n",
      "  MAPE for BlendProperty4: 0.385763\n",
      "  MAPE for BlendProperty5: 0.034650\n",
      "  MAPE for BlendProperty6: 0.308242\n",
      "  MAPE for BlendProperty7: 0.556000\n",
      "  MAPE for BlendProperty8: 0.541123\n",
      "  MAPE for BlendProperty9: 0.918030\n",
      "  MAPE for BlendProperty10: 0.432111\n",
      "\n",
      "✅ Submission file saved as 'submission_tabpfn.csv'\n"
     ]
    }
   ],
   "source": [
    "from tabpfn import TabPFNRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Define inputs and targets\n",
    "X = train.drop(columns=[f'BlendProperty{i}' for i in range(1, 11)])\n",
    "y = train[[f'BlendProperty{i}' for i in range(1, 11)]]\n",
    "X_test = test.drop(columns=['ID'])\n",
    "\n",
    "# 5-Fold setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Placeholders for out-of-fold predictions and test predictions\n",
    "tabpfn_oof = np.zeros(y.shape)\n",
    "tabpfn_test = np.zeros((X_test.shape[0], y.shape[1]))\n",
    "\n",
    "print(\"🚀 Starting TabPFN multi-output regression...\")\n",
    "\n",
    "# Loop over each target\n",
    "for t in range(y.shape[1]):\n",
    "    print(f\"\\n🎯 Training for target: BlendProperty{t+1}\")\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"  Fold {fold+1}/5\")\n",
    "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[train_idx, t], y.iloc[val_idx, t]\n",
    "\n",
    "        # Initialize and train TabPFN\n",
    "        model = TabPFNRegressor(device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model.fit(X_tr.values, y_tr.values)\n",
    "\n",
    "        # Predictions\n",
    "        tabpfn_oof[val_idx, t] = model.predict(X_val.values)\n",
    "        tabpfn_test[:, t] += model.predict(X_test.values) / kf.n_splits\n",
    "\n",
    "# ---------------------------\n",
    "# 🧮 Evaluate MAPE\n",
    "# ---------------------------\n",
    "print(\"\\n📊 MAPE Scores:\")\n",
    "overall_mape = mean_absolute_percentage_error(y, tabpfn_oof)\n",
    "print(f\"✅ Overall MAPE: {overall_mape:.6f}\")\n",
    "\n",
    "for i in range(y.shape[1]):\n",
    "    target_mape = mean_absolute_percentage_error(y.iloc[:, i], tabpfn_oof[:, i])\n",
    "    print(f\"  MAPE for BlendProperty{i+1}: {target_mape:.6f}\")\n",
    "\n",
    "# ---------------------------\n",
    "# 💾 Save Submission\n",
    "# ---------------------------\n",
    "submission = pd.DataFrame(tabpfn_test, columns=[f'BlendProperty{i}' for i in range(1, 11)])\n",
    "submission.insert(0, 'ID', test['ID'])\n",
    "submission.to_csv(\"submission_tabpfn.csv\", index=False)\n",
    "print(\"\\n✅ Submission file saved as 'submission_tabpfn.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
