{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "518100b2",
   "metadata": {},
   "source": [
    "We are gonna revese it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c5a5027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "🚀 Starting Level 1 training (MLP + TabPFN)...\n",
      "🎯 Training Level 1 for target BlendProperty1...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "🎯 Training Level 1 for target BlendProperty2...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "🎯 Training Level 1 for target BlendProperty3...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "🎯 Training Level 1 for target BlendProperty4...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "🎯 Training Level 1 for target BlendProperty5...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "🎯 Training Level 1 for target BlendProperty6...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "🎯 Training Level 1 for target BlendProperty7...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "🎯 Training Level 1 for target BlendProperty8...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "🎯 Training Level 1 for target BlendProperty9...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "🎯 Training Level 1 for target BlendProperty10...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "\n",
      "📊 Level 1 MAPE Scores:\n",
      "  MLP: 3.721405\n",
      "  TabPFN: 0.507453\n",
      "\n",
      "🔄 Preparing Level 2 inputs from Level 1 outputs...\n",
      "\n",
      "🚀 Starting Level 2 stacking (Traditional ML Models)...\n",
      "🎯 Level 2 stacking for BlendProperty1...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "🎯 Level 2 stacking for BlendProperty2...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "🎯 Level 2 stacking for BlendProperty3...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "🎯 Level 2 stacking for BlendProperty4...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "🎯 Level 2 stacking for BlendProperty5...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "🎯 Level 2 stacking for BlendProperty6...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "🎯 Level 2 stacking for BlendProperty7...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "🎯 Level 2 stacking for BlendProperty8...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "🎯 Level 2 stacking for BlendProperty9...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n",
      "🎯 Level 2 stacking for BlendProperty10...\n",
      "  Fold 1/5\n",
      "  Fold 2/5\n",
      "  Fold 3/5\n",
      "  Fold 4/5\n",
      "  Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-23 03:14:47,462] A new study created in memory with name: no-name-02ab7686-470c-483e-a30b-9f53bf99ed74\n",
      "[I 2025-07-23 03:14:47,462] Trial 0 finished with value: 0.5594341312675966 and parameters: {'w_xgb': 0.519481090906018, 'w_lgbm': 0.16222674045768037, 'w_rf': 0.08312604633267351, 'w_et': 0.6893924306329895}. Best is trial 0 with value: 0.5594341312675966.\n",
      "[I 2025-07-23 03:14:47,462] Trial 1 finished with value: 0.5816394331188701 and parameters: {'w_xgb': 0.3001512942721799, 'w_lgbm': 0.7576615790201968, 'w_rf': 0.2519779222362064, 'w_et': 0.02490959201378462}. Best is trial 0 with value: 0.5594341312675966.\n",
      "[I 2025-07-23 03:14:47,470] Trial 2 finished with value: 0.5802200191740488 and parameters: {'w_xgb': 0.948304718579511, 'w_lgbm': 0.15010133137238368, 'w_rf': 0.7645435789618803, 'w_et': 0.1764361878836218}. Best is trial 0 with value: 0.5594341312675966.\n",
      "[I 2025-07-23 03:14:47,473] Trial 3 finished with value: 0.5457927272684723 and parameters: {'w_xgb': 0.3234651451126297, 'w_lgbm': 0.5466480910626158, 'w_rf': 0.9494898583818555, 'w_et': 0.8725828936060738}. Best is trial 3 with value: 0.5457927272684723.\n",
      "[I 2025-07-23 03:14:47,475] Trial 4 finished with value: 0.5495952436902712 and parameters: {'w_xgb': 0.4855444234927594, 'w_lgbm': 0.3751567944262789, 'w_rf': 0.5162019698551132, 'w_et': 0.8661035356136894}. Best is trial 3 with value: 0.5457927272684723.\n",
      "[I 2025-07-23 03:14:47,478] Trial 5 finished with value: 0.5670085935200102 and parameters: {'w_xgb': 0.8485387596366173, 'w_lgbm': 0.8294114786392084, 'w_rf': 0.6551788972449908, 'w_et': 0.5717945803652347}. Best is trial 3 with value: 0.5457927272684723.\n",
      "[I 2025-07-23 03:14:47,481] Trial 6 finished with value: 0.5558048575941829 and parameters: {'w_xgb': 0.4667388639409996, 'w_lgbm': 0.4012336130554167, 'w_rf': 0.9409646078916939, 'w_et': 0.46693731305025843}. Best is trial 3 with value: 0.5457927272684723.\n",
      "[I 2025-07-23 03:14:47,485] Trial 7 finished with value: 0.58587181684411 and parameters: {'w_xgb': 0.7372403570376752, 'w_lgbm': 0.23950469605563685, 'w_rf': 0.09520526599291435, 'w_et': 0.3051265208129822}. Best is trial 3 with value: 0.5457927272684723.\n",
      "[I 2025-07-23 03:14:47,488] Trial 8 finished with value: 0.5627222131429271 and parameters: {'w_xgb': 0.7848469350824312, 'w_lgbm': 0.3482052142103189, 'w_rf': 0.8409518823836584, 'w_et': 0.5553029940329179}. Best is trial 3 with value: 0.5457927272684723.\n",
      "[I 2025-07-23 03:14:47,491] Trial 9 finished with value: 0.5552741861813735 and parameters: {'w_xgb': 0.032583716343523195, 'w_lgbm': 0.43113063328414547, 'w_rf': 0.12423737704558857, 'w_et': 0.3780068984903081}. Best is trial 3 with value: 0.5457927272684723.\n",
      "[I 2025-07-23 03:14:47,511] Trial 10 finished with value: 0.5424608689604195 and parameters: {'w_xgb': 0.008148494921564442, 'w_lgbm': 0.6410770629485931, 'w_rf': 0.422439365093757, 'w_et': 0.9640212065763296}. Best is trial 10 with value: 0.5424608689604195.\n",
      "[I 2025-07-23 03:14:47,531] Trial 11 finished with value: 0.5438219961312087 and parameters: {'w_xgb': 0.013614847427775412, 'w_lgbm': 0.6419666737437785, 'w_rf': 0.337856253333111, 'w_et': 0.9690452226066936}. Best is trial 10 with value: 0.5424608689604195.\n",
      "[I 2025-07-23 03:14:47,549] Trial 12 finished with value: 0.5450678921695076 and parameters: {'w_xgb': 0.0594701630870184, 'w_lgbm': 0.6649042854459827, 'w_rf': 0.35207830475979596, 'w_et': 0.9830646641274517}. Best is trial 10 with value: 0.5424608689604195.\n",
      "[I 2025-07-23 03:14:47,561] Trial 13 finished with value: 0.5563895465964672 and parameters: {'w_xgb': 0.17009119081941082, 'w_lgbm': 0.9884219142845256, 'w_rf': 0.41497072091398224, 'w_et': 0.7465693831396767}. Best is trial 10 with value: 0.5424608689604195.\n",
      "[I 2025-07-23 03:14:47,578] Trial 14 finished with value: 0.5435436221164842 and parameters: {'w_xgb': 0.1923907595308753, 'w_lgbm': 0.5843858956188671, 'w_rf': 0.5683336499625277, 'w_et': 0.9714534143620781}. Best is trial 10 with value: 0.5424608689604195.\n",
      "[I 2025-07-23 03:14:47,593] Trial 15 finished with value: 0.5472896544033377 and parameters: {'w_xgb': 0.2008562903247541, 'w_lgbm': 0.6097081499999956, 'w_rf': 0.5558492333969236, 'w_et': 0.7276502157529607}. Best is trial 10 with value: 0.5424608689604195.\n",
      "[I 2025-07-23 03:14:47,609] Trial 16 finished with value: 0.5335159392656905 and parameters: {'w_xgb': 0.17762972373233343, 'w_lgbm': 0.02529919843577677, 'w_rf': 0.6303781721716483, 'w_et': 0.8591417273566346}. Best is trial 16 with value: 0.5335159392656905.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Level 2 MAPE Scores:\n",
      "  Ridge: 0.523277\n",
      "  Lasso: 0.497542\n",
      "  ElasticNet: 0.533716\n",
      "  BayesianRidge: 0.523995\n",
      "  Huber: 0.513186\n",
      "  RandomForest: 0.557062\n",
      "  ExtraTrees: 0.527078\n",
      "  AdaBoost: 0.697516\n",
      "  GradientBoost: 0.587350\n",
      "  Bagging: 0.498358\n",
      "  KNN: 2.241079\n",
      "  SVR: 0.726280\n",
      "  XGB: 0.644326\n",
      "  LGBM: 0.606273\n",
      "\n",
      "🔍 Starting Level 3 optimization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-23 03:14:47,624] Trial 17 finished with value: 0.5413981875723721 and parameters: {'w_xgb': 0.358730479024323, 'w_lgbm': 0.0247183034335219, 'w_rf': 0.6748545017825933, 'w_et': 0.8372817873352338}. Best is trial 16 with value: 0.5335159392656905.\n",
      "[I 2025-07-23 03:14:47,638] Trial 18 finished with value: 0.541998599017287 and parameters: {'w_xgb': 0.38218213498320835, 'w_lgbm': 0.005438582609265125, 'w_rf': 0.706483837855704, 'w_et': 0.8451814651829908}. Best is trial 16 with value: 0.5335159392656905.\n",
      "[I 2025-07-23 03:14:47,651] Trial 19 finished with value: 0.5574144020326823 and parameters: {'w_xgb': 0.6433510949229798, 'w_lgbm': 0.030929483658237545, 'w_rf': 0.6422058073620432, 'w_et': 0.622162605965395}. Best is trial 16 with value: 0.5335159392656905.\n",
      "[I 2025-07-23 03:14:47,668] Trial 20 finished with value: 0.5527633784822318 and parameters: {'w_xgb': 0.6206041135834943, 'w_lgbm': 0.20846659445899965, 'w_rf': 0.8099144146215248, 'w_et': 0.7840756723700335}. Best is trial 16 with value: 0.5335159392656905.\n",
      "[I 2025-07-23 03:14:47,683] Trial 21 finished with value: 0.5395171289046157 and parameters: {'w_xgb': 0.31204315487186307, 'w_lgbm': 0.006865390732766111, 'w_rf': 0.6989935950847013, 'w_et': 0.8293066336314984}. Best is trial 16 with value: 0.5335159392656905.\n",
      "[I 2025-07-23 03:14:47,699] Trial 22 finished with value: 0.5422537978815897 and parameters: {'w_xgb': 0.2775653283845478, 'w_lgbm': 0.08867086783633438, 'w_rf': 0.6226061480809751, 'w_et': 0.6603040921785007}. Best is trial 16 with value: 0.5335159392656905.\n",
      "[I 2025-07-23 03:14:47,715] Trial 23 finished with value: 0.5462166522365162 and parameters: {'w_xgb': 0.4015545196447675, 'w_lgbm': 0.272245108038411, 'w_rf': 0.7412987125524334, 'w_et': 0.8093055835589642}. Best is trial 16 with value: 0.5335159392656905.\n",
      "[I 2025-07-23 03:14:47,729] Trial 24 finished with value: 0.5356817494726762 and parameters: {'w_xgb': 0.17349275604620953, 'w_lgbm': 0.09387387970287459, 'w_rf': 0.8405341290419935, 'w_et': 0.8704034638217624}. Best is trial 16 with value: 0.5335159392656905.\n",
      "[I 2025-07-23 03:14:47,746] Trial 25 finished with value: 0.5330542024753173 and parameters: {'w_xgb': 0.11586046376951087, 'w_lgbm': 0.08670866559993363, 'w_rf': 0.8637288572694712, 'w_et': 0.9297058365808251}. Best is trial 25 with value: 0.5330542024753173.\n",
      "[I 2025-07-23 03:14:47,761] Trial 26 finished with value: 0.534375175924988 and parameters: {'w_xgb': 0.12918975618756398, 'w_lgbm': 0.1201168647146846, 'w_rf': 0.8756857699953029, 'w_et': 0.9040793054796833}. Best is trial 25 with value: 0.5330542024753173.\n",
      "[I 2025-07-23 03:14:47,776] Trial 27 finished with value: 0.534020839803146 and parameters: {'w_xgb': 0.11474200283404784, 'w_lgbm': 0.1296497612801013, 'w_rf': 0.8959317457096249, 'w_et': 0.9225785149573554}. Best is trial 25 with value: 0.5330542024753173.\n",
      "[I 2025-07-23 03:14:47,788] Trial 28 finished with value: 0.5442791513308929 and parameters: {'w_xgb': 0.1060880499622816, 'w_lgbm': 0.275874808027027, 'w_rf': 0.980482110862412, 'w_et': 0.4603946613975247}. Best is trial 25 with value: 0.5330542024753173.\n",
      "[I 2025-07-23 03:14:47,802] Trial 29 finished with value: 0.5380690610997487 and parameters: {'w_xgb': 0.10625956104213087, 'w_lgbm': 0.1835170347178616, 'w_rf': 0.9112625047180586, 'w_et': 0.6881968421142453}. Best is trial 25 with value: 0.5330542024753173.\n",
      "[I 2025-07-23 03:14:47,820] Trial 30 finished with value: 0.5421325153232893 and parameters: {'w_xgb': 0.24382219039329212, 'w_lgbm': 0.4669040654785371, 'w_rf': 0.7735148637464327, 'w_et': 0.930453284184932}. Best is trial 25 with value: 0.5330542024753173.\n",
      "[I 2025-07-23 03:14:47,835] Trial 31 finished with value: 0.533482091904471 and parameters: {'w_xgb': 0.1051550707438762, 'w_lgbm': 0.12156268344392038, 'w_rf': 0.8854054438625492, 'w_et': 0.9280833706381909}. Best is trial 25 with value: 0.5330542024753173.\n",
      "[I 2025-07-23 03:14:47,845] Trial 32 finished with value: 0.5388452996957682 and parameters: {'w_xgb': 0.0840985249689535, 'w_lgbm': 0.30908826426052827, 'w_rf': 0.9974141595684874, 'w_et': 0.7609252031023035}. Best is trial 25 with value: 0.5330542024753173.\n",
      "[I 2025-07-23 03:14:47,866] Trial 33 finished with value: 0.5365246089408933 and parameters: {'w_xgb': 0.22597617269509435, 'w_lgbm': 0.14642314281323823, 'w_rf': 0.8979889852362848, 'w_et': 0.999700400332846}. Best is trial 25 with value: 0.5330542024753173.\n",
      "[I 2025-07-23 03:14:47,880] Trial 34 finished with value: 0.5334992638804994 and parameters: {'w_xgb': 0.13782799235065926, 'w_lgbm': 0.10253639099354717, 'w_rf': 0.7823545082554734, 'w_et': 0.9206106758271823}. Best is trial 25 with value: 0.5330542024753173.\n",
      "[I 2025-07-23 03:14:47,898] Trial 35 finished with value: 0.5653353149002862 and parameters: {'w_xgb': 0.26525759792386855, 'w_lgbm': 0.0656654487856558, 'w_rf': 0.7745312595747278, 'w_et': 0.021908306790091814}. Best is trial 25 with value: 0.5330542024753173.\n",
      "[I 2025-07-23 03:14:47,913] Trial 36 finished with value: 0.5542251904156967 and parameters: {'w_xgb': 0.15644521851652216, 'w_lgbm': 0.1895932639730461, 'w_rf': 0.8179450586944857, 'w_et': 0.1459946179681394}. Best is trial 25 with value: 0.5330542024753173.\n",
      "[I 2025-07-23 03:14:47,927] Trial 37 finished with value: 0.529327345126976 and parameters: {'w_xgb': 0.06434584618919376, 'w_lgbm': 0.0833665100809563, 'w_rf': 0.5924980387372407, 'w_et': 0.9043923779771522}. Best is trial 37 with value: 0.529327345126976.\n",
      "[I 2025-07-23 03:14:47,943] Trial 38 finished with value: 0.5398743712156396 and parameters: {'w_xgb': 0.06691952314207986, 'w_lgbm': 0.24086415846893883, 'w_rf': 0.016233126373228157, 'w_et': 0.906932567166784}. Best is trial 37 with value: 0.529327345126976.\n",
      "[I 2025-07-23 03:14:47,958] Trial 39 finished with value: 0.5339285706646718 and parameters: {'w_xgb': 0.03902837133520798, 'w_lgbm': 0.06956912580583852, 'w_rf': 0.9401608146980284, 'w_et': 0.7115105679452636}. Best is trial 37 with value: 0.529327345126976.\n",
      "[I 2025-07-23 03:14:47,972] Trial 40 finished with value: 0.5619656327446096 and parameters: {'w_xgb': 0.93057358699167, 'w_lgbm': 0.35639352620899434, 'w_rf': 0.734446599940967, 'w_et': 0.7818786310342616}. Best is trial 37 with value: 0.529327345126976.\n",
      "[I 2025-07-23 03:14:47,991] Trial 41 finished with value: 0.5329933257841967 and parameters: {'w_xgb': 0.13429937239552994, 'w_lgbm': 0.1436640690426571, 'w_rf': 0.5658548897630914, 'w_et': 0.8959008935173439}. Best is trial 37 with value: 0.529327345126976.\n",
      "[I 2025-07-23 03:14:48,007] Trial 42 finished with value: 0.5321564756932794 and parameters: {'w_xgb': 0.12924381712425867, 'w_lgbm': 0.14530678155024837, 'w_rf': 0.48144245623833043, 'w_et': 0.9196568245088049}. Best is trial 37 with value: 0.529327345126976.\n",
      "[I 2025-07-23 03:14:48,023] Trial 43 finished with value: 0.5452171670377866 and parameters: {'w_xgb': 0.43577117242741037, 'w_lgbm': 0.16398651409927895, 'w_rf': 0.47078831741423854, 'w_et': 0.8912364783019916}. Best is trial 37 with value: 0.529327345126976.\n",
      "[I 2025-07-23 03:14:48,038] Trial 44 finished with value: 0.5302677120415193 and parameters: {'w_xgb': 0.006964553212803856, 'w_lgbm': 0.22351792076733748, 'w_rf': 0.49945029798294, 'w_et': 0.9978332941317277}. Best is trial 37 with value: 0.529327345126976.\n",
      "[I 2025-07-23 03:14:48,053] Trial 45 finished with value: 0.5507556984390237 and parameters: {'w_xgb': 0.5434406098025801, 'w_lgbm': 0.22894630798123627, 'w_rf': 0.24061117295897716, 'w_et': 0.9895167081721375}. Best is trial 37 with value: 0.529327345126976.\n",
      "[I 2025-07-23 03:14:48,069] Trial 46 finished with value: 0.5442439210224609 and parameters: {'w_xgb': 0.011830672426411892, 'w_lgbm': 0.2984035195345267, 'w_rf': 0.5209095278203806, 'w_et': 0.3084112332225808}. Best is trial 37 with value: 0.529327345126976.\n",
      "[I 2025-07-23 03:14:48,085] Trial 47 finished with value: 0.5253761879242667 and parameters: {'w_xgb': 0.0012602908144515451, 'w_lgbm': 0.06301304754324603, 'w_rf': 0.45584656778207305, 'w_et': 0.9479682224112527}. Best is trial 47 with value: 0.5253761879242667.\n",
      "[I 2025-07-23 03:14:48,100] Trial 48 finished with value: 0.5419005838709027 and parameters: {'w_xgb': 0.05289497039380637, 'w_lgbm': 0.510283660637081, 'w_rf': 0.4288282804574782, 'w_et': 0.8040283357908056}. Best is trial 47 with value: 0.5253761879242667.\n",
      "[I 2025-07-23 03:14:48,115] Trial 49 finished with value: 0.5433642057284283 and parameters: {'w_xgb': 0.005508502157782292, 'w_lgbm': 0.7704164728544608, 'w_rf': 0.5939961656667134, 'w_et': 0.9558316584686177}. Best is trial 47 with value: 0.5253761879242667.\n",
      "[I 2025-07-23 03:14:48,130] Trial 50 finished with value: 0.531982645904579 and parameters: {'w_xgb': 0.06359712629686004, 'w_lgbm': 0.16728037799454643, 'w_rf': 0.3343917016380229, 'w_et': 0.8691486155569794}. Best is trial 47 with value: 0.5253761879242667.\n",
      "[I 2025-07-23 03:14:48,145] Trial 51 finished with value: 0.5322423786412689 and parameters: {'w_xgb': 0.06780345380909665, 'w_lgbm': 0.16908921885046357, 'w_rf': 0.32681595662845975, 'w_et': 0.8729697069572362}. Best is trial 47 with value: 0.5253761879242667.\n",
      "[I 2025-07-23 03:14:48,162] Trial 52 finished with value: 0.5331276333289642 and parameters: {'w_xgb': 0.06874204610559237, 'w_lgbm': 0.19054298306347983, 'w_rf': 0.32225501415981517, 'w_et': 0.8685552257679674}. Best is trial 47 with value: 0.5253761879242667.\n",
      "[I 2025-07-23 03:14:48,177] Trial 53 finished with value: 0.5389349830605145 and parameters: {'w_xgb': 0.04125925805248753, 'w_lgbm': 0.39827160585534715, 'w_rf': 0.2699972479685028, 'w_et': 0.9603056718642444}. Best is trial 47 with value: 0.5253761879242667.\n",
      "[I 2025-07-23 03:14:48,196] Trial 54 finished with value: 0.5255086181052226 and parameters: {'w_xgb': 0.010455211820539406, 'w_lgbm': 0.047936336927689144, 'w_rf': 0.3794266194661763, 'w_et': 0.8431321249748}. Best is trial 47 with value: 0.5253761879242667.\n",
      "[I 2025-07-23 03:14:48,210] Trial 55 finished with value: 0.5411368629778972 and parameters: {'w_xgb': 0.21412260714474252, 'w_lgbm': 0.05158971211985271, 'w_rf': 0.3837540285059422, 'w_et': 0.5324370369032436}. Best is trial 47 with value: 0.5253761879242667.\n",
      "[I 2025-07-23 03:14:48,225] Trial 56 finished with value: 0.5542162562494062 and parameters: {'w_xgb': 0.00019401792945017426, 'w_lgbm': 0.9730122977597397, 'w_rf': 0.4832582356831448, 'w_et': 0.6286497161979043}. Best is trial 47 with value: 0.5253761879242667.\n",
      "[I 2025-07-23 03:14:48,241] Trial 57 finished with value: 0.5277061787196764 and parameters: {'w_xgb': 0.03588914583047215, 'w_lgbm': 0.0460992788771691, 'w_rf': 0.18714807186344884, 'w_et': 0.8256310552158563}. Best is trial 47 with value: 0.5253761879242667.\n",
      "[I 2025-07-23 03:14:48,258] Trial 58 finished with value: 0.5279949890632912 and parameters: {'w_xgb': 0.029645250984302526, 'w_lgbm': 0.05882045525344215, 'w_rf': 0.18159627000327272, 'w_et': 0.8307155534780281}. Best is trial 47 with value: 0.5253761879242667.\n",
      "[I 2025-07-23 03:14:48,276] Trial 59 finished with value: 0.5278229618602122 and parameters: {'w_xgb': 0.033125524075517165, 'w_lgbm': 0.03910534114672628, 'w_rf': 0.15070268002366316, 'w_et': 0.7519533035819573}. Best is trial 47 with value: 0.5253761879242667.\n",
      "[I 2025-07-23 03:14:48,288] Trial 60 finished with value: 0.5281949622087034 and parameters: {'w_xgb': 0.033499688453643595, 'w_lgbm': 0.047659457685313725, 'w_rf': 0.15771610645034362, 'w_et': 0.7376185153866188}. Best is trial 47 with value: 0.5253761879242667.\n",
      "[I 2025-07-23 03:14:48,310] Trial 61 finished with value: 0.5276319322915002 and parameters: {'w_xgb': 0.025803614944234957, 'w_lgbm': 0.0423553047129365, 'w_rf': 0.14837403199381127, 'w_et': 0.7467059906458308}. Best is trial 47 with value: 0.5253761879242667.\n",
      "[I 2025-07-23 03:14:48,326] Trial 62 finished with value: 0.5279125207050369 and parameters: {'w_xgb': 0.03908256841999459, 'w_lgbm': 0.031020914051935543, 'w_rf': 0.1408237837196089, 'w_et': 0.7423371761392594}. Best is trial 47 with value: 0.5253761879242667.\n",
      "[I 2025-07-23 03:14:48,337] Trial 63 finished with value: 0.5292936064936261 and parameters: {'w_xgb': 0.08978584180603404, 'w_lgbm': 0.0009257227620419681, 'w_rf': 0.1784354587107252, 'w_et': 0.6609804737562315}. Best is trial 47 with value: 0.5253761879242667.\n",
      "[I 2025-07-23 03:14:48,357] Trial 64 finished with value: 0.5293553455879143 and parameters: {'w_xgb': 0.035558750853206894, 'w_lgbm': 0.03323650371277153, 'w_rf': 0.053174797790804376, 'w_et': 0.8161088846047299}. Best is trial 47 with value: 0.5253761879242667.\n",
      "[I 2025-07-23 03:14:48,374] Trial 65 finished with value: 0.5364702498029915 and parameters: {'w_xgb': 0.17482863462079462, 'w_lgbm': 0.03808615506588661, 'w_rf': 0.11086429681394488, 'w_et': 0.7824108789235394}. Best is trial 47 with value: 0.5253761879242667.\n",
      "[I 2025-07-23 03:14:48,393] Trial 66 finished with value: 0.5664928779607006 and parameters: {'w_xgb': 0.7907328677413032, 'w_lgbm': 0.10693361193735883, 'w_rf': 0.16695517093028478, 'w_et': 0.7103874542108144}. Best is trial 47 with value: 0.5253761879242667.\n",
      "[I 2025-07-23 03:14:48,410] Trial 67 finished with value: 0.528533343947559 and parameters: {'w_xgb': 0.08932029334245598, 'w_lgbm': 0.0042949619149410465, 'w_rf': 0.21412896022610683, 'w_et': 0.7509809425601104}. Best is trial 47 with value: 0.5253761879242667.\n",
      "[I 2025-07-23 03:14:48,425] Trial 68 finished with value: 0.54019365016325 and parameters: {'w_xgb': 0.15554064533877607, 'w_lgbm': 0.06367360591658597, 'w_rf': 0.06538697462541253, 'w_et': 0.5993413768527762}. Best is trial 47 with value: 0.5253761879242667.\n",
      "[I 2025-07-23 03:14:48,442] Trial 69 finished with value: 0.5295873332174919 and parameters: {'w_xgb': 0.034406824876000774, 'w_lgbm': 0.113581811072276, 'w_rf': 0.2840447028585181, 'w_et': 0.8178545239165815}. Best is trial 47 with value: 0.5253761879242667.\n",
      "[I 2025-07-23 03:14:48,458] Trial 70 finished with value: 0.5257048370598997 and parameters: {'w_xgb': 0.0041812813173298345, 'w_lgbm': 0.02491721951299387, 'w_rf': 0.14076545535395543, 'w_et': 0.6651127882127724}. Best is trial 47 with value: 0.5253761879242667.\n",
      "[I 2025-07-23 03:14:48,474] Trial 71 finished with value: 0.528831625096827 and parameters: {'w_xgb': 0.02659912086382026, 'w_lgbm': 0.05824870892642338, 'w_rf': 0.1362881005300724, 'w_et': 0.6755088121651416}. Best is trial 47 with value: 0.5253761879242667.\n",
      "[I 2025-07-23 03:14:48,494] Trial 72 finished with value: 0.5257010407811427 and parameters: {'w_xgb': 0.003589550374276147, 'w_lgbm': 0.03387797269073558, 'w_rf': 0.18240199570806795, 'w_et': 0.7066694547606478}. Best is trial 47 with value: 0.5253761879242667.\n",
      "[I 2025-07-23 03:14:48,512] Trial 73 finished with value: 0.5248307243464277 and parameters: {'w_xgb': 0.0013235600102549545, 'w_lgbm': 0.025928964792011427, 'w_rf': 0.22923243309663655, 'w_et': 0.6202996189377039}. Best is trial 73 with value: 0.5248307243464277.\n",
      "[I 2025-07-23 03:14:48,528] Trial 74 finished with value: 0.5286997136945537 and parameters: {'w_xgb': 0.0029523797597705206, 'w_lgbm': 0.08873236025794966, 'w_rf': 0.21493021183009353, 'w_et': 0.5784902410694399}. Best is trial 73 with value: 0.5248307243464277.\n",
      "[I 2025-07-23 03:14:48,542] Trial 75 finished with value: 0.53148201388175 and parameters: {'w_xgb': 0.08793478511681445, 'w_lgbm': 0.006842978665730758, 'w_rf': 0.08866151314184578, 'w_et': 0.6367567701504389}. Best is trial 73 with value: 0.5248307243464277.\n",
      "[I 2025-07-23 03:14:48,558] Trial 76 finished with value: 0.536717987685906 and parameters: {'w_xgb': 0.09422817048410359, 'w_lgbm': 0.12081578716930053, 'w_rf': 0.20780823943888632, 'w_et': 0.5116710166339007}. Best is trial 73 with value: 0.5248307243464277.\n",
      "[I 2025-07-23 03:14:48,573] Trial 77 finished with value: 0.5253723270203859 and parameters: {'w_xgb': 0.0010294752085226245, 'w_lgbm': 0.029022828679777873, 'w_rf': 0.26018410952180676, 'w_et': 0.45804682308122346}. Best is trial 73 with value: 0.5248307243464277.\n",
      "[I 2025-07-23 03:14:48,591] Trial 78 finished with value: 0.5703954979362484 and parameters: {'w_xgb': 0.673054463153143, 'w_lgbm': 0.08529760687020754, 'w_rf': 0.29578726643372416, 'w_et': 0.4392862196217605}. Best is trial 73 with value: 0.5248307243464277.\n",
      "[I 2025-07-23 03:14:48,607] Trial 79 finished with value: 0.5328916979669925 and parameters: {'w_xgb': 0.06370690801485268, 'w_lgbm': 0.0004665568269342779, 'w_rf': 0.3771790639060427, 'w_et': 0.4067596856157235}. Best is trial 73 with value: 0.5248307243464277.\n",
      "[I 2025-07-23 03:14:48,621] Trial 80 finished with value: 0.5421713588293805 and parameters: {'w_xgb': 0.15100938312774226, 'w_lgbm': 0.027469472032979596, 'w_rf': 0.2427512927261764, 'w_et': 0.3449929513868278}. Best is trial 73 with value: 0.5248307243464277.\n",
      "[I 2025-07-23 03:14:48,639] Trial 81 finished with value: 0.5278852660672644 and parameters: {'w_xgb': 0.005875383134209797, 'w_lgbm': 0.07736250514057937, 'w_rf': 0.19646173920512713, 'w_et': 0.6958449244534503}. Best is trial 73 with value: 0.5248307243464277.\n",
      "[I 2025-07-23 03:14:48,653] Trial 82 finished with value: 0.5301186830540001 and parameters: {'w_xgb': 0.04770261921437566, 'w_lgbm': 0.028068974426517023, 'w_rf': 0.10888803941259399, 'w_et': 0.48332854582008467}. Best is trial 73 with value: 0.5248307243464277.\n",
      "[I 2025-07-23 03:14:48,669] Trial 83 finished with value: 0.5434496451275057 and parameters: {'w_xgb': 0.1155093375326087, 'w_lgbm': 0.13327082157189707, 'w_rf': 0.024940009248272332, 'w_et': 0.552389040782842}. Best is trial 73 with value: 0.5248307243464277.\n",
      "[I 2025-07-23 03:14:48,687] Trial 84 finished with value: 0.5530892011210047 and parameters: {'w_xgb': 0.5483232169877139, 'w_lgbm': 0.048322157173557895, 'w_rf': 0.2522023656890386, 'w_et': 0.7659338533180076}. Best is trial 73 with value: 0.5248307243464277.\n",
      "[I 2025-07-23 03:14:48,702] Trial 85 finished with value: 0.5333447161557199 and parameters: {'w_xgb': 0.08039513686725067, 'w_lgbm': 0.10823614337632043, 'w_rf': 0.43900446488347356, 'w_et': 0.6058786657305941}. Best is trial 73 with value: 0.5248307243464277.\n",
      "[I 2025-07-23 03:14:48,717] Trial 86 finished with value: 0.5265316835493145 and parameters: {'w_xgb': 0.0013794798926170257, 'w_lgbm': 0.07522535311931536, 'w_rf': 0.36894110062165086, 'w_et': 0.7187336137785874}. Best is trial 73 with value: 0.5248307243464277.\n",
      "[I 2025-07-23 03:14:48,733] Trial 87 finished with value: 0.527513593142565 and parameters: {'w_xgb': 0.0017213579642523418, 'w_lgbm': 0.09189911527867733, 'w_rf': 0.3692716139395818, 'w_et': 0.6499273557478729}. Best is trial 73 with value: 0.5248307243464277.\n",
      "[I 2025-07-23 03:14:48,747] Trial 88 finished with value: 0.54928745442312 and parameters: {'w_xgb': 0.0007198623781361327, 'w_lgbm': 0.6974827433397606, 'w_rf': 0.36512632555093316, 'w_et': 0.649282314390554}. Best is trial 73 with value: 0.5248307243464277.\n",
      "[I 2025-07-23 03:14:48,762] Trial 89 finished with value: 0.5297477339849908 and parameters: {'w_xgb': 0.05751015156646177, 'w_lgbm': 0.0812355063101337, 'w_rf': 0.3988248550137896, 'w_et': 0.6814805117667864}. Best is trial 73 with value: 0.5248307243464277.\n",
      "[I 2025-07-23 03:14:48,781] Trial 90 finished with value: 0.5320814061065812 and parameters: {'w_xgb': 0.024230212207773657, 'w_lgbm': 0.1343002222599927, 'w_rf': 0.4540964510893158, 'w_et': 0.5785980829809241}. Best is trial 73 with value: 0.5248307243464277.\n",
      "[I 2025-07-23 03:14:48,796] Trial 91 finished with value: 0.5271070836456296 and parameters: {'w_xgb': 0.018645500869581853, 'w_lgbm': 0.06417243443090426, 'w_rf': 0.3126651985301424, 'w_et': 0.7073356841492334}. Best is trial 73 with value: 0.5248307243464277.\n",
      "[I 2025-07-23 03:14:48,814] Trial 92 finished with value: 0.5276613403195344 and parameters: {'w_xgb': 0.0010082285436877648, 'w_lgbm': 0.10113135064621441, 'w_rf': 0.35103469660087083, 'w_et': 0.7280968344686194}. Best is trial 73 with value: 0.5248307243464277.\n",
      "[I 2025-07-23 03:14:48,829] Trial 93 finished with value: 0.531846591712318 and parameters: {'w_xgb': 0.11172401576510738, 'w_lgbm': 0.07447152137886687, 'w_rf': 0.3036677055371274, 'w_et': 0.7119053041149795}. Best is trial 73 with value: 0.5248307243464277.\n",
      "[I 2025-07-23 03:14:48,843] Trial 94 finished with value: 0.5291618117034106 and parameters: {'w_xgb': 0.060517688771198896, 'w_lgbm': 0.01563697274817827, 'w_rf': 0.4162151763708691, 'w_et': 0.6096426994310915}. Best is trial 73 with value: 0.5248307243464277.\n",
      "[I 2025-07-23 03:14:48,862] Trial 95 finished with value: 0.5272647057713876 and parameters: {'w_xgb': 0.021242686607853056, 'w_lgbm': 0.061389595524505, 'w_rf': 0.3111175935893034, 'w_et': 0.6624480423690131}. Best is trial 73 with value: 0.5248307243464277.\n",
      "[I 2025-07-23 03:14:48,877] Trial 96 finished with value: 0.5349459094994087 and parameters: {'w_xgb': 0.08103282719421917, 'w_lgbm': 0.15664578578466304, 'w_rf': 0.26596589882919813, 'w_et': 0.6477442596652035}. Best is trial 73 with value: 0.5248307243464277.\n",
      "[I 2025-07-23 03:14:48,895] Trial 97 finished with value: 0.527724375494161 and parameters: {'w_xgb': 0.022505261595524937, 'w_lgbm': 0.06620015438399268, 'w_rf': 0.3970891948303953, 'w_et': 0.6620807594722725}. Best is trial 73 with value: 0.5248307243464277.\n",
      "[I 2025-07-23 03:14:48,910] Trial 98 finished with value: 0.5317075904466324 and parameters: {'w_xgb': 0.05887759183019398, 'w_lgbm': 0.09835013355573449, 'w_rf': 0.3119842237099127, 'w_et': 0.5441970038690125}. Best is trial 73 with value: 0.5248307243464277.\n",
      "[I 2025-07-23 03:14:48,926] Trial 99 finished with value: 0.5270536077444544 and parameters: {'w_xgb': 0.04910798540195407, 'w_lgbm': 0.02545832335680212, 'w_rf': 0.2759890808222897, 'w_et': 0.6969849891739616}. Best is trial 73 with value: 0.5248307243464277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Best MAPE: 0.524831\n",
      "🎯 Best weights:\n",
      "  w_xgb: 0.0013\n",
      "  w_lgbm: 0.0259\n",
      "  w_rf: 0.2292\n",
      "  w_et: 0.6203\n",
      "\n",
      "📊 Normalized weights:\n",
      "  w_xgb: 0.0015\n",
      "  w_lgbm: 0.0296\n",
      "  w_rf: 0.2614\n",
      "  w_et: 0.7075\n",
      "\n",
      "🎉 Final ensemble MAPE: 0.524831\n",
      "\n",
      "📊 Individual target MAPE scores:\n",
      "  BlendProperty1: 1.275035\n",
      "  BlendProperty2: 0.318356\n",
      "  BlendProperty3: 0.585924\n",
      "  BlendProperty4: 0.412230\n",
      "  BlendProperty5: 0.054391\n",
      "  BlendProperty6: 0.347585\n",
      "  BlendProperty7: 0.531392\n",
      "  BlendProperty8: 0.487688\n",
      "  BlendProperty9: 0.774070\n",
      "  BlendProperty10: 0.461636\n",
      "\n",
      "💾 Submission file saved as 'submission_reversed_ensemble.csv'\n",
      "\n",
      "🎯 Reversed Ensemble Summary:\n",
      "  Level 1: MLP + TabPFN as base models\n",
      "  Level 2: 14 traditional ML models stacking on Level 1 outputs\n",
      "  Level 3: Optimized weighted ensemble of top Level 2 performers\n",
      "  Final MAPE: 0.524831\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, BayesianRidge, HuberRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, GradientBoostingRegressor, BaggingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import torch\n",
    "from tabpfn import TabPFNRegressor\n",
    "\n",
    "print(\"Loading data...\")\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "X = train.drop([f'BlendProperty{i}' for i in range(1, 11)], axis=1)\n",
    "y = train[[f'BlendProperty{i}' for i in range(1, 11)]]\n",
    "X_test = test.drop(['ID'], axis=1)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"🚀 Starting Level 1 training (MLP + TabPFN)...\")\n",
    "\n",
    "# Level 1: MLP and TabPFN as base models\n",
    "level1_names = ['MLP', 'TabPFN']\n",
    "level1_oof = {name: np.zeros(y.shape) for name in level1_names}\n",
    "level1_test = {name: np.zeros((X_test.shape[0], y.shape[1])) for name in level1_names}\n",
    "\n",
    "for t in range(y.shape[1]):\n",
    "    print(f\"🎯 Training Level 1 for target BlendProperty{t+1}...\")\n",
    "    for fold, (tr_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"  Fold {fold+1}/5\")\n",
    "        X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[tr_idx, t], y.iloc[val_idx, t]\n",
    "\n",
    "        # MLP\n",
    "        mlp = MLPRegressor(hidden_layer_sizes=(512, 256, 128), activation='relu', max_iter=500, random_state=42)\n",
    "        mlp.fit(X_tr, y_tr)\n",
    "        level1_oof['MLP'][val_idx, t] = mlp.predict(X_val)\n",
    "        level1_test['MLP'][:, t] += mlp.predict(X_test) / kf.n_splits\n",
    "\n",
    "        # TabPFN\n",
    "        tabpfn = TabPFNRegressor(device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        tabpfn.fit(X_tr, y_tr.values)\n",
    "        level1_oof['TabPFN'][val_idx, t] = tabpfn.predict(X_val)\n",
    "        level1_test['TabPFN'][:, t] += tabpfn.predict(X_test) / kf.n_splits\n",
    "\n",
    "print(\"\\n📊 Level 1 MAPE Scores:\")\n",
    "for name in level1_names:\n",
    "    mape = mean_absolute_percentage_error(y, level1_oof[name])\n",
    "    print(f\"  {name}: {mape:.6f}\")\n",
    "\n",
    "print(\"\\n🔄 Preparing Level 2 inputs from Level 1 outputs...\")\n",
    "stack_X = np.concatenate([level1_oof[name] for name in level1_names], axis=1)\n",
    "stack_X_test = np.concatenate([level1_test[name] for name in level1_names], axis=1)\n",
    "\n",
    "print(\"\\n🚀 Starting Level 2 stacking (Traditional ML Models)...\")\n",
    "\n",
    "# Level 2: Traditional ML models as stacking models\n",
    "level2_names = [\n",
    "    'Ridge', 'Lasso', 'ElasticNet', 'BayesianRidge', 'Huber',\n",
    "    'RandomForest', 'ExtraTrees', 'AdaBoost', 'GradientBoost', 'Bagging',\n",
    "    'KNN', 'SVR', 'XGB', 'LGBM'\n",
    "]\n",
    "level2_oof = {name: np.zeros(y.shape) for name in level2_names}\n",
    "level2_test = {name: np.zeros((X_test.shape[0], y.shape[1])) for name in level2_names}\n",
    "\n",
    "for t in range(y.shape[1]):\n",
    "    print(f\"🎯 Level 2 stacking for BlendProperty{t+1}...\")\n",
    "    for fold, (tr_idx, val_idx) in enumerate(kf.split(stack_X)):\n",
    "        print(f\"  Fold {fold+1}/5\")\n",
    "        X_tr, X_val = stack_X[tr_idx], stack_X[val_idx]\n",
    "        y_tr, y_val = y.iloc[tr_idx, t], y.iloc[val_idx, t]\n",
    "\n",
    "        # Ridge\n",
    "        ridge = Ridge(alpha=1.0)\n",
    "        ridge.fit(X_tr, y_tr)\n",
    "        level2_oof['Ridge'][val_idx, t] = ridge.predict(X_val)\n",
    "        level2_test['Ridge'][:, t] += ridge.predict(stack_X_test) / kf.n_splits\n",
    "\n",
    "        # Lasso\n",
    "        lasso = Lasso(alpha=0.1)\n",
    "        lasso.fit(X_tr, y_tr)\n",
    "        level2_oof['Lasso'][val_idx, t] = lasso.predict(X_val)\n",
    "        level2_test['Lasso'][:, t] += lasso.predict(stack_X_test) / kf.n_splits\n",
    "\n",
    "        # ElasticNet\n",
    "        elastic = ElasticNet(alpha=0.1)\n",
    "        elastic.fit(X_tr, y_tr)\n",
    "        level2_oof['ElasticNet'][val_idx, t] = elastic.predict(X_val)\n",
    "        level2_test['ElasticNet'][:, t] += elastic.predict(stack_X_test) / kf.n_splits\n",
    "\n",
    "        # BayesianRidge\n",
    "        bayesian = BayesianRidge()\n",
    "        bayesian.fit(X_tr, y_tr)\n",
    "        level2_oof['BayesianRidge'][val_idx, t] = bayesian.predict(X_val)\n",
    "        level2_test['BayesianRidge'][:, t] += bayesian.predict(stack_X_test) / kf.n_splits\n",
    "\n",
    "        # Huber\n",
    "        huber = HuberRegressor()\n",
    "        huber.fit(X_tr, y_tr)\n",
    "        level2_oof['Huber'][val_idx, t] = huber.predict(X_val)\n",
    "        level2_test['Huber'][:, t] += huber.predict(stack_X_test) / kf.n_splits\n",
    "\n",
    "        # RandomForest\n",
    "        rf = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "        rf.fit(X_tr, y_tr)\n",
    "        level2_oof['RandomForest'][val_idx, t] = rf.predict(X_val)\n",
    "        level2_test['RandomForest'][:, t] += rf.predict(stack_X_test) / kf.n_splits\n",
    "\n",
    "        # ExtraTrees\n",
    "        et = ExtraTreesRegressor(n_estimators=50, random_state=42)\n",
    "        et.fit(X_tr, y_tr)\n",
    "        level2_oof['ExtraTrees'][val_idx, t] = et.predict(X_val)\n",
    "        level2_test['ExtraTrees'][:, t] += et.predict(stack_X_test) / kf.n_splits\n",
    "\n",
    "        # AdaBoost\n",
    "        ada = AdaBoostRegressor(random_state=42)\n",
    "        ada.fit(X_tr, y_tr)\n",
    "        level2_oof['AdaBoost'][val_idx, t] = ada.predict(X_val)\n",
    "        level2_test['AdaBoost'][:, t] += ada.predict(stack_X_test) / kf.n_splits\n",
    "\n",
    "        # GradientBoosting\n",
    "        gb = GradientBoostingRegressor(random_state=42)\n",
    "        gb.fit(X_tr, y_tr)\n",
    "        level2_oof['GradientBoost'][val_idx, t] = gb.predict(X_val)\n",
    "        level2_test['GradientBoost'][:, t] += gb.predict(stack_X_test) / kf.n_splits\n",
    "\n",
    "        # Bagging\n",
    "        bag = BaggingRegressor(random_state=42)\n",
    "        bag.fit(X_tr, y_tr)\n",
    "        level2_oof['Bagging'][val_idx, t] = bag.predict(X_val)\n",
    "        level2_test['Bagging'][:, t] += bag.predict(stack_X_test) / kf.n_splits\n",
    "\n",
    "        # KNN\n",
    "        knn = KNeighborsRegressor()\n",
    "        knn.fit(X_tr, y_tr)\n",
    "        level2_oof['KNN'][val_idx, t] = knn.predict(X_val)\n",
    "        level2_test['KNN'][:, t] += knn.predict(stack_X_test) / kf.n_splits\n",
    "\n",
    "        # SVR\n",
    "        svr = SVR()\n",
    "        svr.fit(X_tr, y_tr)\n",
    "        level2_oof['SVR'][val_idx, t] = svr.predict(X_val)\n",
    "        level2_test['SVR'][:, t] += svr.predict(stack_X_test) / kf.n_splits\n",
    "\n",
    "        # XGBoost\n",
    "        xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "        xgb_model.fit(X_tr, y_tr)\n",
    "        level2_oof['XGB'][val_idx, t] = xgb_model.predict(X_val)\n",
    "        level2_test['XGB'][:, t] += xgb_model.predict(stack_X_test) / kf.n_splits\n",
    "\n",
    "        # LightGBM\n",
    "        lgb_model = lgb.LGBMRegressor(random_state=42, verbose=-1)\n",
    "        lgb_model.fit(X_tr, y_tr)\n",
    "        level2_oof['LGBM'][val_idx, t] = lgb_model.predict(X_val)\n",
    "        level2_test['LGBM'][:, t] += lgb_model.predict(stack_X_test) / kf.n_splits\n",
    "\n",
    "print(\"\\n📊 Level 2 MAPE Scores:\")\n",
    "for name in level2_names:\n",
    "    mape = mean_absolute_percentage_error(y, level2_oof[name])\n",
    "    print(f\"  {name}: {mape:.6f}\")\n",
    "\n",
    "print(\"\\n🔍 Starting Level 3 optimization...\")\n",
    "\n",
    "# Prepare Level 3 inputs - select top performers from Level 2\n",
    "level3_oof = np.concatenate([\n",
    "    level2_oof['XGB'], \n",
    "    level2_oof['LGBM'], \n",
    "    level2_oof['RandomForest'],\n",
    "    level2_oof['ExtraTrees']\n",
    "], axis=1)\n",
    "\n",
    "level3_test = np.concatenate([\n",
    "    level2_test['XGB'], \n",
    "    level2_test['LGBM'], \n",
    "    level2_test['RandomForest'],\n",
    "    level2_test['ExtraTrees']\n",
    "], axis=1)\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest weights for each component\n",
    "    w_xgb = trial.suggest_float('w_xgb', 0.0, 1.0)\n",
    "    w_lgbm = trial.suggest_float('w_lgbm', 0.0, 1.0) \n",
    "    w_rf = trial.suggest_float('w_rf', 0.0, 1.0)\n",
    "    w_et = trial.suggest_float('w_et', 0.0, 1.0)\n",
    "    \n",
    "    # Normalize weights\n",
    "    total_weight = w_xgb + w_lgbm + w_rf + w_et\n",
    "    if total_weight == 0:\n",
    "        return float('inf')\n",
    "    \n",
    "    w_xgb /= total_weight\n",
    "    w_lgbm /= total_weight\n",
    "    w_rf /= total_weight\n",
    "    w_et /= total_weight\n",
    "    \n",
    "    # Create weighted ensemble\n",
    "    ensemble_pred = (w_xgb * level2_oof['XGB'] + \n",
    "                    w_lgbm * level2_oof['LGBM'] + \n",
    "                    w_rf * level2_oof['RandomForest'] + \n",
    "                    w_et * level2_oof['ExtraTrees'])\n",
    "    \n",
    "    # Calculate MAPE\n",
    "    mape = mean_absolute_percentage_error(y, ensemble_pred)\n",
    "    return mape\n",
    "\n",
    "# Optimize weights\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(f\"\\n✅ Best MAPE: {study.best_value:.6f}\")\n",
    "print(\"🎯 Best weights:\")\n",
    "best_params = study.best_params\n",
    "for param, value in best_params.items():\n",
    "    print(f\"  {param}: {value:.4f}\")\n",
    "\n",
    "# Normalize best weights\n",
    "total_weight = sum(best_params.values())\n",
    "normalized_weights = {k: v/total_weight for k, v in best_params.items()}\n",
    "\n",
    "print(\"\\n📊 Normalized weights:\")\n",
    "for param, value in normalized_weights.items():\n",
    "    print(f\"  {param}: {value:.4f}\")\n",
    "\n",
    "# Create final ensemble predictions\n",
    "final_test = (normalized_weights['w_xgb'] * level2_test['XGB'] + \n",
    "              normalized_weights['w_lgbm'] * level2_test['LGBM'] + \n",
    "              normalized_weights['w_rf'] * level2_test['RandomForest'] + \n",
    "              normalized_weights['w_et'] * level2_test['ExtraTrees'])\n",
    "\n",
    "# Final validation score\n",
    "final_oof = (normalized_weights['w_xgb'] * level2_oof['XGB'] + \n",
    "             normalized_weights['w_lgbm'] * level2_oof['LGBM'] + \n",
    "             normalized_weights['w_rf'] * level2_oof['RandomForest'] + \n",
    "             normalized_weights['w_et'] * level2_oof['ExtraTrees'])\n",
    "\n",
    "final_mape = mean_absolute_percentage_error(y, final_oof)\n",
    "print(f\"\\n🎉 Final ensemble MAPE: {final_mape:.6f}\")\n",
    "\n",
    "print(\"\\n📊 Individual target MAPE scores:\")\n",
    "for i in range(y.shape[1]):\n",
    "    target_mape = mean_absolute_percentage_error(y.iloc[:, i], final_oof[:, i])\n",
    "    print(f\"  BlendProperty{i+1}: {target_mape:.6f}\")\n",
    "\n",
    "# Save submission\n",
    "submission = pd.DataFrame(final_test, columns=[f'BlendProperty{i}' for i in range(1, 11)])\n",
    "submission.insert(0, 'ID', test['ID'])\n",
    "submission.to_csv(\"submission_reversed_ensemble.csv\", index=False)\n",
    "print(\"\\n💾 Submission file saved as 'submission_reversed_ensemble.csv'\")\n",
    "\n",
    "print(\"\\n🎯 Reversed Ensemble Summary:\")\n",
    "print(f\"  Level 1: MLP + TabPFN as base models\")\n",
    "print(f\"  Level 2: {len(level2_names)} traditional ML models stacking on Level 1 outputs\") \n",
    "print(f\"  Level 3: Optimized weighted ensemble of top Level 2 performers\")\n",
    "print(f\"  Final MAPE: {final_mape:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
